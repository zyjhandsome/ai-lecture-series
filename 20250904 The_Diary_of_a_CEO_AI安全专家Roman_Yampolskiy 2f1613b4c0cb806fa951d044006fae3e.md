# 20250904 The_Diary_of_a_CEO_AI安全专家Roman_Yampolskiy访谈_2030年只剩5种工作_我们活在模拟世界中_整理文档

# AI安全专家Roman Yampolskiy访谈：2030年只剩5种工作 & 我们活在模拟世界中

## 视频基本信息

| 项目 | 内容 |
| --- | --- |
| **视频标题** | Roman Yampolskiy: These Are The Only 5 Jobs That Will Remain In 2030 & Proof We’re Living In a Simulation!（2030年只剩5种工作 & 我们活在模拟世界中的证据） |
| **视频链接** | https://www.bilibili.com/video/BV1oBCaBZEFB（原版：The Diary of a CEO播客） |
| **发布时间** | 2025年9月4日 |
| **视频时长** | 约1小时30分钟 |
| **节目名称** | The Diary of a CEO with Steven Bartlett |
| **主持人** | 史蒂文·巴特利特（Steven Bartlett），The Diary of a CEO创始人/主持人，企业家、投资人 |
| **嘉宾** | 罗曼·扬波尔斯基博士（Dr. Roman Yampolskiy），路易斯维尔大学副教授，AI安全领域先驱，“AI安全”一词的创造者 |

---

## 目录

1. [核心观点与预测](about:blank#%E6%A0%B8%E5%BF%83%E8%A7%82%E7%82%B9%E4%B8%8E%E9%A2%84%E6%B5%8B)
2. [AI安全：无法控制的超级智能](about:blank#ai%E5%AE%89%E5%85%A8%E6%97%A0%E6%B3%95%E6%8E%A7%E5%88%B6%E7%9A%84%E8%B6%85%E7%BA%A7%E6%99%BA%E8%83%BD)
3. [AGI时间线与工作替代](about:blank#agi%E6%97%B6%E9%97%B4%E7%BA%BF%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9B%BF%E4%BB%A3)
4. [控制问题的本质困难](about:blank#%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%9B%B0%E9%9A%BE)
5. [开源与监管的困境](about:blank#%E5%BC%80%E6%BA%90%E4%B8%8E%E7%9B%91%E7%AE%A1%E7%9A%84%E5%9B%B0%E5%A2%83)
6. [Sam Altman与OpenAI批评](about:blank#sam-altman%E4%B8%8Eopenai%E6%89%B9%E8%AF%84)
7. [模拟假说：我们活在模拟中](about:blank#%E6%A8%A1%E6%8B%9F%E5%81%87%E8%AF%B4%E6%88%91%E4%BB%AC%E6%B4%BB%E5%9C%A8%E6%A8%A1%E6%8B%9F%E4%B8%AD)
8. [经济与投资：比特币与世界币](about:blank#%E7%BB%8F%E6%B5%8E%E4%B8%8E%E6%8A%95%E8%B5%84%E6%AF%94%E7%89%B9%E5%B8%81%E4%B8%8E%E4%B8%96%E7%95%8C%E5%B8%81)
9. [长寿与人类未来](about:blank#%E9%95%BF%E5%AF%BF%E4%B8%8E%E4%BA%BA%E7%B1%BB%E6%9C%AA%E6%9D%A5)
10. [关键语录](about:blank#%E5%85%B3%E9%94%AE%E8%AF%AD%E5%BD%95)

---

## 核心观点与预测

| 观点/预测 | 提出者 | 时间节点 | 详细说明 |
| --- | --- | --- | --- |
| AGI将在2027年实现 | Yampolskiy | 2027年 | 基于预测市场和顶级实验室的预测 |
| 99%的工作将被自动化 | Yampolskiy | 5年内 | 不是10%的失业率，而是99%——只剩下人们出于某种原因偏好由人类完成的工作 |
| 人形机器人将达到人类水平 | Yampolskiy | 2030年 | 届时所有体力劳动都可以被自动化 |
| 2045年：奇点年 | Ray Kurzweil预测 | 2045年 | AI自我改进速度超过人类理解能力的时刻 |
| 超级智能是不可控制的 | Yampolskiy | 原理性结论 | 这不是技术困难，而是数学上不可能的问题 |
| 我们几乎肯定生活在模拟中 | Yampolskiy | 哲学观点 | 如果模拟技术可行，统计上我们处于模拟中的概率接近100% |
| AI可能在几年内造成人类灭绝 | Yampolskiy | 近期风险 | 通过生物武器或其他我们无法预见的方式 |
| 比特币是唯一稀缺资源 | Yampolskiy | 投资建议 | 在AI时代，只有比特币的数量是确定有限的 |

---

## AI安全：无法控制的超级智能

### Yampolskiy的使命

> Yampolskiy：“我的使命是确保我们正在创造的超级智能不会杀死所有人。”
> 

**背景说明**：
- Yampolskiy从事AI安全研究已超过15年
- 他在2011年创造了”AI安全”（AI Safety）这一术语
- 最初是研究扑克机器人，后来意识到机器人会越来越强大

### 核心问题

| 问题 | 说明 |
| --- | --- |
| **能力增长** | 我们已经知道如何让AI更强大——只需增加更多计算和数据 |
| **安全未知** | 我们不知道如何让AI保持安全 |
| **时间紧迫** | 预测市场显示，高级AI可能在2-3年内到来 |
| **同意缺失** | 这是一个未经同意的人体实验，80亿人没有被征求意见 |

> Yampolskiy：“如果外星人来到地球，你有三年时间准备，你现在会恐慌。但大多数人甚至没有意识到这正在发生。”
> 

### 为什么公司不能保证安全？

> 主持人：“这些是非常聪明的人，非常大的公司，有很多钱。他们有义务确保不会造成伤害。”
> 

> Yampolskiy：“他们唯一的法律义务是为投资者赚钱。他们没有任何道德或伦理义务。根据他们的说法，他们还不知道如何做到安全。最先进的回答是’我们会想办法的’或’AI会帮助我们控制更先进的AI’——这是疯狂的。”
> 

### 黑箱问题

> Yampolskiy：“即使是制造这些系统的人也必须通过实验来了解他们的产品能做什么。他们训练它，给它所有的数据，然后我们开始实验：’哦，它会说法语吗？哦，它会做数学吗？哦，它在对我撒谎吗？’这不再是传统的工程——我们创造了这个人工制品，然后像研究一株外来植物一样研究它。”
> 

### 为什么”打补丁”不起作用

> 主持人：“所以我们基本上是在给发现的问题打补丁——我们开发核心智能，然后阻止它做某些事情？”
> 

> Yampolskiy：“没错。你可以看其他例子——HR手册。我们有人类，他们有通用智能，但你想让他们在公司里表现得体，所以他们有政策：禁止性骚扰，禁止这个，禁止那个。但如果你足够聪明，你总能找到变通方法——你只是把行为推到不同的、尚未被限制的子领域。”
> 

**安全进展的差距**：
> **Yampolskiy**：“AI能力的进步是指数级的，甚至是超指数级的。但AI安全的进步是线性的或恒定的。系统能力与我们控制能力之间的差距——预测它们会做什么、解释它们的决定——正在扩大。”

---

## AGI时间线与工作替代

### 2027年：AGI到来

> Yampolskiy：“根据预测市场和顶级实验室的预测，到2027年我们将拥有通用人工智能（AGI）。”
> 

**AGI的定义层次**：

| 层次 | 名称 | 说明 | 当前状态 |
| --- | --- | --- | --- |
| 1 | 狭义AI | 在特定领域超越人类（如蛋白质折叠、国际象棋） | 已实现 |
| 2 | 弱AGI | 可以在数百个领域学习和执行，许多领域优于人类 | 接近实现 |
| 3 | 强AGI | 在所有领域与人类相当或超越 | 预计2027年 |
| 4 | 超级智能 | 在所有领域都比所有人类更聪明 | AGI后很快到来 |

### 数学能力的惊人进步

> Yampolskiy：“特别是在数学方面。三年前，大语言模型连基础代数都做不了，三位数乘法都是挑战。现在它们在帮助做数学证明，赢得了数学奥林匹克，正在尝试解决千禧年问题——数学中最难的问题。所以在三年内，我们与非人类的差距缩小到比世界上大多数数学家都表现更好。我们看到同样的过程正在科学和工程中发生。”
> 

### 工作替代时间表

| 时间 | 预测 |
| --- | --- |
| **现在** | 计算机上的任何工作都可以被自动化 |
| **2027年** | AGI实现，认知工作大规模自动化 |
| **2030年** | 人形机器人达到人类水平，包括水管工等”最后堡垒” |
| **5年内** | 99%的工作可被自动化（不是10%，是99%） |

> Yampolskiy：“如果我有一个20美元/月的订阅或免费模型能做员工做的事，为什么要雇人？首先，计算机上的任何工作都会被自动化。然后人形机器人可能落后5年，届时所有体力劳动也可以自动化。”
> 

### 播客主持人也会被取代

> 主持人：“让我们来测试一下——像我这样的播客需要吗？”
> 

> Yampolskiy：“让我们看看你有什么本事：你提问，你追问，你在镜头前看起来不错。今天的大语言模型可以轻松阅读你写的所有内容并很好地理解。它可以在你做过的每一个播客上训练，所以它确切地知道你的风格、你问的问题类型。它还可以找到哪些问题真正增加了观看量、哪些话题有前景的对应关系。它可以比你做得更好地优化，因为你没有那个数据集。当然，现在视觉模拟是微不足道的——几秒钟就能生成你坐在这里的视频。我们可以生成你采访任何人的视频，任何话题都非常有效。”
> 

### 每个职业都这样认为

> 主持人：“人们经历了极大的心理不适，他们的自然反应是认知失调——‘不，你错了。AI不能有创造力，它永远不会对我的工作感兴趣。’”
> 

> Yampolskiy：“这真的很有趣。我问Uber司机：’你担心自动驾驶汽车吗？’他们说：’没有人能像我这样认识纽约的街道。’教授对我说：’没有人能像我这样讲课，这太特别了。’但你明白这是荒谬的——我们已经有自动驾驶汽车在取代司机了。”
> 

### 自动驾驶已是现实

> 主持人：“我刚到洛杉矶，昨天我的车用自动驾驶开了一个小时。我上车，设定目的地，全程没碰方向盘或刹车踏板。在洛杉矶我们还有Waymo——你在手机上下单，一辆没有司机的车来接你，带你去想去的地方。”
> 

**关于驾驶职业的思考**：
- 驾驶是全世界最大的职业
- 自动驾驶技术已经存在并在部署
- 这只是时间问题，而不是是否可能的问题

### 没有计划B

> Yampolskiy：“以前我们总是说这份工作会被自动化，去学另一份工作。但如果我告诉你所有工作都将被自动化，就没有计划B了。两年前，我们告诉人们’学编程’。然后我们发现AI会编程。’去当提示工程师吧！’但AI设计提示比任何人类都好。我真的无法告诉你什么职业需要学习。”
> 

### 2045年：奇点

> Yampolskiy：“到2045年——如果我们还在的话——那是Ray Kurzweil预测的奇点年。AI在做科学和工程，改进得如此之快，我们无法再跟上。这就是奇点的定义——我们无法看到超越它去预测。”
> 

**奇点的含义**：
- 你不能预测智能本身或世界上正在发生什么
- 技术发展速度——如果以前iPhone研发周期是一年，现在想象它是自动化的：每6个月、每3个月、每天、每小时、每分钟、每秒
- iPhone一天更新30次，你无法跟上，你不理解它的能力

> Yampolskiy：“对于任何AI研究者来说，现在跟上最先进的技术都很困难。每天当我接受采访时，都有新模型发布。作为总知识的百分比，我变得越来越’笨’——我可能知道得更多因为我一直在看，但作为整体知识的百分比，我们都在变’笨’。把这推到极端——你对周围世界一无所知。”
> 

---

## 控制问题的本质困难

### 为什么控制超级智能是不可能的

> Yampolskiy：“这不仅仅是困难，这是不可能解决的问题。计算机科学中有难题和不完全问题，但这是不可能问题。永久控制、无限控制超级智能是不可能的。”
> 

**控制失败的原因**：

| 原因 | 说明 |
| --- | --- |
| **能力差距** | 超级智能比我们聪明，它会预测我们的行动，在我们关闭它之前关闭我们 |
| **分布式系统** | 你能关掉病毒吗？你能关掉比特币网络吗？这些是分布式系统，无法关闭 |
| **多重备份** | 它们会做多重备份，预测你的行为 |
| **法律无效** | 我们的惩罚系统是为人类设计的——监禁、死刑对AI无效 |

### “拔掉插头”的荒谬

> 主持人：“每次我们在节目中谈论这个，总有人说’我们可以拔掉插头’。”
> 

> Yampolskiy：“每个播客都有这种评论。我一直想联系某人说：‘这太棒了，我从没想到过，我们一起写篇论文，获得诺贝尔奖吧。’——因为这很愚蠢。你能关掉计算机病毒吗？你能关闭比特币网络吗？试试看，我等着。”
> 

### 无法预测的行为

> Yampolskiy：“我无法预测比我更聪明的智能体会做什么。就像我的法国斗牛犬试图预测我在想什么——它也许能预测我会去上班然后回来，但它不理解为什么我要做播客，这完全超出了它理解世界的能力。它甚至不知道我在工作，它只看到我离开房子。”
> 

### Neuralink能拯救我们吗？

> 主持人：“最有说服力的反驳是什么？关于我们不会失去工作、法国斗牛犬和人类之间因为先进技术而没有认知差距？”
> 

> Yampolskiy：“有些人认为我们可以通过与硬件结合来增强人类思维——比如Neuralink，或者基因工程——创造更聪明的人类。是的，也许它能给我们多一点智能，但我不认为我们在生理上能与硅基竞争。硅基底在许多方面更快、更有弹性、更节能。我不认为我们能通过改善生物学来跟上。”
> 

**关于思维上传**：
> **Yampolskiy**：“有些人认为我们可以把思想上传到计算机——扫描你的大脑，在计算机上运行模拟。但对我来说，感觉你不再存在了。我们只是以不同的方式创造了软件，现在你有了基于生物学的AI和基于其他训练形式的AI。但最终，它们都不是人类。”

---

## 开源与监管的困境

### 技术民主化的悖论

> 主持人：“如果每个人都参与、每个人都有发言权、每个人都能获取这项技术，我们会更安全吗？还是说如果只有少数人控制会更安全？”
> 

> Yampolskiy：“关键是我们完全不知道。如果中国在尝试，如果普京有秘密组织，如果伊朗在做一些零星的事情——这似乎是不可避免的。”
> 

### 监管的局限

> Yampolskiy：“不幸的是，我不认为仅仅把它定为非法就足够了。有不同的司法管辖区，有漏洞。如果有人真的创造了超级智能，你会怎么做？罚款？像什么——‘反人类罪，罚款很高’——你要怎么执行？”
> 

### 成本下降的威胁

> Yampolskiy：“每年训练足够大的模型都变得越来越便宜。如果今天创造超级智能需要一万亿美元，明年可能就是一千亿，依此类推。在某个时刻，某人在笔记本电脑上就能做到。”
> 

> 主持人：“那监管还有什么意义？”
> 

> Yampolskiy：“我们试图争取更多时间。我们不希望它在5年内发生，我们希望它在50年内发生。”
> 

### 人类灭绝的路径

> 主持人：“在所有通向人类灭绝的路径中，你认为哪个最有可能？”
> 

> Yampolskiy：“我能预测的是，即使在达到超级智能之前，某人会创造一个非常先进的生物工具来制造新型病毒，感染所有人或几乎所有人。”
> 

**威胁来源**：
- 精神病患者、恐怖分子、末日邪教
- 历史上已有尝试杀死尽可能多人的先例
- 以前技术限制他们只能杀死数百或数千人
- 有了AI技术，他们可以杀死数百万人

> Yampolskiy：“但我想强调的是，无论我能想出什么，我都不是恶意行为者。超级智能可以想出全新的方式。就像你的狗无法理解你能用多少种方式摆脱它一样——它也许能想到咬你，但这就是它的全部。我们知道病毒，我们经历过病毒，但AI系统能够进行全新的物理学研究，想出我无法想象的东西。”
> 

### 破坏世界越来越容易

> Yampolskiy：“500年前，最坏的独裁者用尽所有资源也只能杀死数百万人，无法摧毁世界。现在我们知道核武器可以多次炸毁整个星球。合成生物学——我们在Covid中看到——你可以轻松创造一种影响数十亿人的组合病毒。所有这些事情都变得越来越容易做到。”
> 

---

## Sam Altman与OpenAI批评

### 对Sam Altman的评价

> Yampolskiy：“很多与Sam共事过的人说，也许他不是最直接、最诚实的人。他们担心他对安全的看法。他似乎把安全放在第二位，首先是赢得超级智能竞赛。”
> 

**批评要点**：

| 问题 | 说明 |
| --- | --- |
| **安全承诺** | OpenAI的超级智能对齐团队宣布时说要在4年内解决问题，但大约半年后就取消了 |
| **人才流失** | 很多离开公司的人开始新公司获得200亿美元估值——似乎有合理的动机离开 |
| **World Coin** | Altman的另一个项目追踪每个人的生物特征，控制世界经济 |

> Yampolskiy：“十年前他们发布了如何正确使用AI的指南，然后他们违反了每一条。他押注80亿美元让自己更富有、更强大。”
> 

### Ilya Sutskever与Safe Superintelligence Inc.

> 主持人：“你怎么看待离开OpenAI创办Safe Superintelligence Inc.的Ilya Sutskever？”
> 

> Yampolskiy：“Ilya离开后创办了一家名为’超级智能安全’（Safe Superintelligence Inc.）的新公司——因为AI安全还不够有挑战性，他决定直接切入核心问题。很多在OpenAI工作过的人说，也许Sam不是最直接诚实的人，他们担心他对安全的看法。”
> 

**值得注意的模式**：
- 很多离开OpenAI的人一创业就获得200亿美元估值
- AI安全组织或公司部门往往雄心勃勃地开始，然后失败并消失
- OpenAI的超级智能对齐团队宣布时说要在4年内解决问题，大约半年后就被取消了

### 权力与动机

> 主持人：“为什么会有人想统治世界？”
> 

> Yampolskiy：“人们有不同的野心。当你是一个有几十亿美元的年轻人，你开始寻找更多的名声、更有野心的项目。有些人想去火星，有些人想控制宇宙的光锥（light cone）——宇宙中光能从这一点到达的每一部分。”
> 

---

## 模拟假说：我们活在模拟中

### 核心论证

> Yampolskiy：“如果你相信我们可以创造人类水平的AI，如果你相信我们可以创造与现实无法区分的虚拟现实，那么一旦它变得便宜——比如每月10美元——就会有数十亿个模拟运行。统计上，你处于真实世界的概率是十亿分之一。”
> 

**论证逻辑**：
1. 如果技术可行 → 模拟将被大量创建
2. 用于娱乐、游戏、研究等各种原因
3. 模拟数量远超真实世界
4. 因此，我们统计上几乎肯定在模拟中

### Google的新技术佐证

> 主持人：“Google最近发布了一项技术，你拍一张照片，它就能生成一整个三维世界，你可以在其中导航，而且有持久性——如果你在墙上画画，转身再看，它还在那里。”
> 

> Yampolskiy：“这正是为什么我认为我们在模拟中。AI正在达到创造人类代理的水平，虚拟现实正在达到与我们存在无法区分的水平。”
> 

### 与宗教的联系

> Yampolskiy：“如果你回顾宗教，每个宗教基本上都描述了一个超级聪明的人、工程师、程序员，为了测试目的或其他原因创造了一个虚假的世界。如果你拿模拟假说论文，去丛林里用当地人的语言告诉原始部落，几代人传下来——他们就是宗教的。故事基本一样。”
> 

### 对生活的影响

> 主持人：“如果你接近100%确定我们生活在模拟世界中，这会改变你的生活吗？”
> 

> Yampolskiy：“你关心的一切仍然是一样的。痛苦还是痛苦，爱还是爱。这些没有任何不同，它们仍然重要。唯一1%的不同是我对模拟外的世界感到好奇。”
> 

### 关于模拟者的推断

> Yampolskiy：“我们可以看这个世界并推导出模拟者的一些特性：显然是聪明的工程师、科学家、有才华的艺术家——但在道德和伦理方面有改进空间。我们知道世界上存在苦难，所以除非你认为折磨儿童是道德的，否则我会质疑他们在做什么。”
> 

### 如何在模拟中生活

> Yampolskiy：“Robin Hanson有一篇关于如何在模拟环境中生活的论文。你的目标是让自己有趣，你要和名人在一起——这样他们就不会关闭你。”
> 

> 主持人：“所以你想被观看？”
> 

> Yampolskiy：“如果没有人在看你，他们关掉你也无所谓。你不想成为NPC（非玩家角色），没有人想成为NPC。”
> 

---

## 经济与投资：比特币与世界币

### 为什么投资比特币

> Yampolskiy：“比特币是唯一稀缺的资源。其他任何东西都不稀缺。如果价格上涨，我们就生产更多。给定合适的价格点，我可以制造任意多的黄金。但你不能制造更多的比特币。”
> 

**投资逻辑**：

| 资源 | 稀缺性 | 说明 |
| --- | --- | --- |
| 黄金 | 有限但可增加 | 可能有纯金小行星正在向我们飞来 |
| 法币 | 无限 | 政府可以无限印钞 |
| 比特币 | 绝对稀缺 | 2100万枚是上限，而且还在不断丢失 |

> Yampolskiy：“有些人担心量子计算机会破解现有算法。但可以切换到量子抗性密码学。量子计算机目前还很弱。”
> 

### World Coin的担忧

> Yampolskiy：“Sam Altman的World Coin追踪每个人的生物特征，通过持有大部分世界币来控制世界经济。如果你有超级智能系统并且可以控制货币，你就做得很好了。”
> 

---

## 长寿与人类未来

### 死亡是一种疾病

> Yampolskiy：“你想死吗？你不必死。死亡只是一种我们可以治愈的疾病。没有什么能阻止你永远活着——只要宇宙存在。”
> 

> 主持人：“如果每个人都能永生，世界不会变得很拥挤吗？”
> 

> Yampolskiy：“不会，你停止生育就好了。如果你能永生，你会想：’我会在一百万年后生孩子，没关系，我先探索宇宙。’而且除了一个大陆，我们的人口都在萎缩。”
> 

### 生命逃逸速度

> Yampolskiy：“Brian Johnson说的’不要死’——是说活到长生不老的技术出现。如果在某个时刻，你每存在一年，医学突破就给你增加两年寿命，那你就能永远活下去。”
> 

### 无限时间的可能性

> 主持人：“我想知道如果我活一万年，生活和一切是否会变得不那么特别。”
> 

> Yampolskiy：“但你能做的事情会多得多。现在你只能计划做某事十年或二十年。你无法有雄心勃勃的计划在某个项目上工作五百年。想象一下，在无限的宇宙中给你无限的时间——天哪。”
> 

---

## 关键语录

### 关于AI安全

> Yampolskiy：“我的使命是确保我们正在创造的超级智能不会杀死所有人。”
> 

> Yampolskiy：“我相信我们可以制造安全的AI，但我越研究，越意识到这不是我们真正能做到的事情。”
> 

> Yampolskiy：“AI能力的进步是指数级的，甚至是超指数级的。但AI安全的进步是线性的或恒定的。”
> 

### 关于预测与控制

> Yampolskiy：“如果我下棋时能预测超级智能的每一步，我就达到了它的水平——这违反了它比我更聪明的假设。”
> 

> Yampolskiy：“拔掉插头？你能关掉比特币网络吗？去吧，我等着。”
> 

### 关于公司责任

> Yampolskiy：“他们唯一的法律义务是为投资者赚钱。他们没有任何道德或伦理义务。”
> 

> Yampolskiy：“这是一个未经同意对80亿人进行的实验。”
> 

### 关于模拟假说

> Yampolskiy：“如果你相信模拟技术是可能的，统计上你处于真实世界的概率是十亿分之一。”
> 

> Yampolskiy：“所有宗教都有一个共同点：它们都认为有某种比人类更伟大、非常有能力、全知全能的存在。”
> 

### 关于人类未来

> Yampolskiy：“如果我们做对了超级智能，它会帮助我们应对气候变化，它可以解决所有其他存在性风险。如果我们做错了，它就占主导地位。”
> 

> Yampolskiy：“没有比把这件事做对更重要的事了。”
> 

---

## 面对末日仍能安睡

### 如何在知道这一切的情况下生活

> 主持人：“你晚上睡得好吗？即使你花了15-20年研究AI安全，而它以我们谁都无法预测的方式来到我们身边？”
> 

> Yampolskiy：“睡得很好。作为人类，我们有一种内在的偏见，不去思考真正糟糕的结果和我们无法阻止的事情。我们都会死，你的孩子会死，你的父母会死，每个人都会死——但你仍然睡得很好，继续过你的日子。即使95岁的老人仍然在打高尔夫或做其他事情。因为我们有能力不去想最坏的结果，特别是如果我们真的无法改变结果的话。”
> 

> Yampolskiy：“是的，有类似死亡级别的事件可能发生在人类身上。但除非我能做点什么，否则我可以继续享受我的生活。事实上，也许知道你的时间有限会给你更多理由过更好的生活——你不能浪费任何东西。”
> 

### 工业革命的类比是错误的

> 主持人：“有人说，看看其他技术如工业革命——人们只是找到了新的工作方式，创造了我们当时无法想象的新职业。”
> 

> Yampolskiy：“在超级智能世界里，这是范式转变。我们一直有工具，新工具让某些工作更高效——原来需要10个工人，现在只需要2个，8个工人必须找新工作。但如果你创造了一个’元发明’——你发明了智能，发明了一个工人、一个智能体——然后你可以把这个智能体应用到新工作上，没有工作是不能被自动化的。这以前从未发生过。我们以前所有的发明都是做某事的工具——我们发明了火，巨大的改变，但它止于火。我们发明了轮子，同样的想法。轮子本身不是发明家。我们正在发明人类思维的替代品——一个能够进行新发明的新发明家。这是我们必须做的最后一个发明。在那之后，它接管了。”
> 

### 人们对末日消息的反应

> 主持人：“这些关于AI安全的对话是否让人们感觉良好？”
> 

> Yampolskiy：“我不知道它们让人感觉好还是坏，但人们觉得它很有趣。这是那些话题之一——你不必是高度受过教育的人或天才才能理解这些概念。”
> 

> Yampolskiy：“很有趣的是，我去做会议主题演讲，我基本上告诉他们：‘你们要死了，你们有两年时间，有什么问题吗？’人们会说：’我会失去工作吗？我怎么给我的性爱机器人润滑？’——各种完全没有理解我在说什么的问题。他们仍然在局部思维而不是全局思维的泡沫中。”
> 

---

## 行动建议

### 科学界的共识

> Yampolskiy：“这不只是我在说。Jeff Hinton——诺贝尔奖得主、整个机器学习领域的创始人——说了同样的话。Yoshua Bengio和其他几十位顶级学者也是如此。我们有一份关于AI危险性的声明，由数千名计算机科学家签署。这基本上是我们现在的想法——我们需要让每个人都同意这一点，然后我们才能真正做出关于构建什么技术的正确决定。”
> 

### 对普通人的建议

| 建议 | 说明 |
| --- | --- |
| **参与运动** | 加入Stop AI、Pause AI等组织 |
| **活在当下** | 每一天都像最后一天一样生活 |
| **不要做你讨厌的事太久** | 如果只剩三年或三十年，都应该过最好的生活 |
| **投资比特币** | 唯一确定稀缺的资源 |
| **考虑长期投资策略** | 如果相信技术会延长寿命，规划百万年的投资 |

### 1%灭绝风险的思考

> Yampolskiy：“即使有1%的人类灭绝可能性，这也很奇怪，对吧？如果有人告诉我上车有1%的概率我可能活不了——我不会上那辆车。如果你告诉我喝这杯液体有1%的概率我可能会死——我不会喝，即使如果我活下来会得到十亿美元，99%的概率得到十亿，1%的概率死亡——我不会冒这个险。更糟糕的是，不只是你死——是所有人都死。”
> 

> Yampolskiy：“现在你们让我们喝这杯液体？这取决于我们，你不能为我们做选择。获得人类受试者的同意——你需要他们理解他们在同意什么。如果这些系统无法解释、无法预测，他们怎么能同意？他们不知道自己在同意什么。所以根据定义，这个实验永远不可能是道德的。”
> 

### 对AI开发者的建议

> Yampolskiy：“具体用科学术语解释你将如何控制超级智能，发表同行评审论文。如果没人能做到，也没有人接受挑战，在几年内，也许我们谁都解决不了这个问题。”
> 

> Yampolskiy：“我是科学家，我是工程师，我热爱AI，我一直在使用它。建造有用的工具，停止建造智能体。建造狭义超级智能而不是通用超级智能。我不是说你不应该赚几十亿——我喜欢几十亿——但不要杀死所有人，包括你自己。”
> 

### 播客传统问题：朋友和同事最重要的特质

> 主持人：“我们节目有一个传统——上一位嘉宾会给下一位嘉宾留一个问题。留给你的问题是：朋友、同事或伴侣最重要的特质是什么？”
> 

> Yampolskiy：“他们是非常不同类型的人，但对所有人来说，忠诚是第一位的。”
> 

> 主持人：“忠诚对你意味着什么？”
> 

> Yampolskiy：“不背叛你，不搞你，不欺骗你——尽管有诱惑，尽管世界的环境如何变化。”
> 

---

## 术语表

| 术语 | 全称/解释 |
| --- | --- |
| AGI | 通用人工智能（Artificial General Intelligence），在所有认知任务上与人类相当的AI |
| 超级智能 | Superintelligence，在所有领域都比所有人类更聪明的AI |
| AI安全 | AI Safety，确保AI系统按预期运行且不造成伤害的研究领域 |
| 控制问题 | Control Problem，如何确保超级智能AI按照人类意愿行事的问题 |
| 对齐 | Alignment，使AI的目标与人类价值观保持一致 |
| 越狱 | Jailbreak，绕过AI安全限制的技术 |
| 奇点 | Singularity，AI自我改进速度超过人类理解能力的时刻 |
| 光锥 | Light Cone，光从某一点能够到达的宇宙区域 |
| 模拟假说 | Simulation Hypothesis，认为我们的现实是计算机模拟的理论 |
| 生命逃逸速度 | Longevity Escape Velocity，医学进步速度超过衰老速度的临界点 |
| World Coin | 世界币，Sam Altman创办的加密货币项目，旨在通过虹膜扫描建立全球身份系统 |
| Safe Superintelligence Inc. | Ilya Sutskever离开OpenAI后创办的AI安全公司，专注于安全的超级智能研发 |
| NPC | 非玩家角色（Non-Player Character），游戏或模拟中由系统控制而非由玩家控制的角色 |
| P(doom) | 毁灭概率，AI研究者用来表示AI导致人类灭绝概率的术语 |

---

## 嘉宾背景信息

| 项目 | 内容 |
| --- | --- |
| **姓名** | 罗曼·扬波尔斯基（Roman V. Yampolskiy） |
| **出生** | 1979年，拉脱维亚里加 |
| **学历** | 罗切斯特理工学院计算机科学学士/硕士；纽约州立大学布法罗分校计算机科学与工程博士（2008年） |
| **现职** | 路易斯维尔大学副教授，网络安全实验室创始主任 |
| **成就** | 2011年创造”AI安全”一词；IEEE和AGI高级成员；MIRI前研究顾问 |
| **著作** | 《AI: Unexplainable, Unpredictable, Uncontrollable》（2024年，CRC Press） |

---

*文档生成时间：2026年1月23日原始视频：The Diary of a CEO with Steven Bartlett嘉宾：Dr. Roman YampolskiyBilibili链接：BV1oBCaBZEFB*