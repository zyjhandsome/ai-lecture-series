# 20260202 Lex_Fridman_Podcast_490_2026年AI现状_整理文档

# 2026年AI现状：LLM、编程、Scaling Laws、中国、智能体、GPU与AGI

## 视频基本信息

| 项目 | 内容 |
| --- | --- |
| **视频标题** | State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI | Lex Fridman Podcast #490 |
| **视频链接** | https://www.youtube.com/watch?v=EV7WhVT270Q |
| **发布时间** | 2026年2月2日 |
| **视频时长** | 4小时25分钟12秒 |
| **节目名称** | Lex Fridman Podcast |
| **嘉宾** | **Sebastian Raschka**（机器学习研究员、《Build a Large Language Model from Scratch》和《Build a Reasoning Model from Scratch》作者）、**Nathan Lambert**（Allen Institute for AI 后训练负责人、《Reinforcement Learning from Human Feedback》作者） |
| **主持人** | **Lex Fridman** |

---

## 目录

1. [核心观点与预测](about:blank#%E6%A0%B8%E5%BF%83%E8%A7%82%E7%82%B9%E4%B8%8E%E9%A2%84%E6%B5%8B)
2. [中美AI竞争格局](about:blank#%E4%B8%AD%E7%BE%8Eai%E7%AB%9E%E4%BA%89%E6%A0%BC%E5%B1%80)
3. [主流AI模型对比](about:blank#%E4%B8%BB%E6%B5%81ai%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94)
4. [AI编程工具](about:blank#ai%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7)
5. [开源与闭源模型格局](about:blank#%E5%BC%80%E6%BA%90%E4%B8%8E%E9%97%AD%E6%BA%90%E6%A8%A1%E5%9E%8B%E6%A0%BC%E5%B1%80)
6. [Transformer架构演进](about:blank#transformer%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B)
7. [Scaling Laws的现状与未来](about:blank#scaling-laws%E7%9A%84%E7%8E%B0%E7%8A%B6%E4%B8%8E%E6%9C%AA%E6%9D%A5)
8. [预训练、中训练与后训练](about:blank#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%AD%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83)
9. [后训练前沿：RLVR与RLHF](about:blank#%E5%90%8E%E8%AE%AD%E7%BB%83%E5%89%8D%E6%B2%BFrlvr%E4%B8%8Erlhf)
10. [AI学习与职业建议](about:blank#ai%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%81%8C%E4%B8%9A%E5%BB%BA%E8%AE%AE)
11. [硅谷AI工作文化](about:blank#%E7%A1%85%E8%B0%B7ai%E5%B7%A5%E4%BD%9C%E6%96%87%E5%8C%96)
12. [新兴技术方向](about:blank#%E6%96%B0%E5%85%B4%E6%8A%80%E6%9C%AF%E6%96%B9%E5%90%91)
13. [AGI时间线与展望](about:blank#agi%E6%97%B6%E9%97%B4%E7%BA%BF%E4%B8%8E%E5%B1%95%E6%9C%9B)
14. [AI商业化与行业整合](about:blank#ai%E5%95%86%E4%B8%9A%E5%8C%96%E4%B8%8E%E8%A1%8C%E4%B8%9A%E6%95%B4%E5%90%88)
15. [ADAM项目：美国开源AI倡议](about:blank#adam%E9%A1%B9%E7%9B%AE%E7%BE%8E%E5%9B%BD%E5%BC%80%E6%BA%90ai%E5%80%A1%E8%AE%AE)
16. [人类文明的未来](about:blank#%E4%BA%BA%E7%B1%BB%E6%96%87%E6%98%8E%E7%9A%84%E6%9C%AA%E6%9D%A5)
17. [关键语录](about:blank#%E5%85%B3%E9%94%AE%E8%AF%AD%E5%BD%95)
18. [术语表](about:blank#%E6%9C%AF%E8%AF%AD%E8%A1%A8)

---

## 核心观点与预测

| 观点/预测 | 提出者 | 时间节点 | 详细说明 |
| --- | --- | --- | --- |
| 2026年不会有任何公司独占技术优势 | Sebastian | 当前 | 研究人员频繁换工作，思想会流动，差异化因素将是预算和硬件资源 |
| 中国开源模型将持续数年 | Nathan | 2026年+ | 中国公司将开源视为获取国际影响力和市场份额的方式 |
| Gemini将继续蚕食ChatGPT市场份额 | Nathan | 2026年 | Google的规模优势和TPU自研能力提供成本优势 |
| Anthropic将在软件和企业端保持成功 | Nathan | 2026年 | Claude Code的成功验证了其代码优先策略 |
| 预训练Scaling Laws仍然有效 | Nathan | 长期 | 已验证13个数量级的计算规模，没有理由认为会停止 |
| 超级编码AI可能在2031年前实现 | Nathan | 2031年（均值预测） | AI27报告的预测，从之前的2027-2028推迟 |
| 2026年将出现$2,000订阅服务 | Nathan | 2026年 | 从$200订阅再10倍增长 |
| 软件工程将转向系统设计和目标导向 | Nathan | 未来数年 | 软件开发正在经历根本性变革 |

---

## 中美AI竞争格局

### DeepSeek时刻的影响

2025年1月，中国开源公司DeepSeek发布R1模型，以更少的计算资源和更低的成本实现了接近最先进的性能，震惊了整个AI行业。

> **Sebastian**：“DeepSeek赢得了开源模型社区的心，因为他们分享这些开放权重模型。”
> 

**关键洞察**：
- DeepSeek以约500万美元的云计算市场价格完成预训练
- 这一事件催生了中国更多科技公司发布强大的开源模型
- 中国现在有Kimi Moonshot、MiniMax、Z.ai（GLM模型）等多个竞争者

### 中国开源模型的战略意义

| 因素 | 说明 |
| --- | --- |
| **商业策略** | 美国顶级科技公司出于安全考虑不会付费使用中国API，开源是获取影响力的途径 |
| **许可证优势** | 中国模型的开源许可证更加宽松，没有使用量限制等附加条件 |
| **国际影响力** | 政府支持开源以建立国际技术影响力 |
| **成本优势** | 在中国可能使用更少的GPU做推理，导致速度较慢但成本更低 |

### 竞争格局现状

**Nathan的观察**：
- DeepSeek虽然仍然很强，但正在失去”中国开源之王”的地位
- Kimi Moonshot、MiniMax、Z.ai近几个月表现更亮眼
- DeepSeek由对冲基金Highflyer Capital支持，运营神秘但技术报告公开

---

## 主流AI模型对比

### 各模型的使用场景

| 模型 | 最佳用途 | 使用者偏好 |
| --- | --- | --- |
| **ChatGPT** | 快速问答、日常任务 | Sebastian使用Auto模式处理日常任务 |
| **ChatGPT Pro** | 深度检查、文献验证 | Sebastian用于详细校对和事实核查 |
| **GPT-5.2 Thinking** | 信息查询、论文查找 | Nathan专门使用思考模式 |
| **Claude Opus 4.5** | 代码编写、哲学讨论 | Nathan称其为”几乎达到了meme级的热度” |
| **Gemini** | 快速解释、背景知识 | 擅长长上下文中的”大海捞针” |
| **Grok 4 Heavy** | 高难度调试 | 解决其他模型无法解决的复杂问题 |

### Claude Opus 4.5现象

> **Nathan**：“Claude Opus 4.5的热度绝对疯狂……Anthropic以代码为核心的策略正在获得回报。”
> 

**关键特点**：
- 2025年11月末发布后热度持续攀升
- 在X/Twitter上成为开发者社区的宠儿
- Claude Code使其成为编程领域的标杆
- 但需区分社交媒体热度与实际用户基数——ChatGPT和Gemini服务的普通用户群体更庞大

### Gemini 3的市场地位

- 2025年末发布，发布时营销声势浩大
- Google拥有结构性优势：自研TPU、数据中心先发优势
- NVIDIA芯片利润率极高，Google可以端到端优化降低成本
- 长上下文能力从30%提升到70%，表现优异

---

## AI编程工具

### 主要工具对比

| 工具 | 特点 | 使用体验 |
| --- | --- | --- |
| **Cursor** | IDE集成、Composer模型每90分钟更新一次权重 | Lex半数时间使用 |
| **Claude Code** | 更具代理性、端到端自动化 | 像有一个编程伙伴，减少孤独感 |
| **Codeium** | VS Code插件、聊天界面访问仓库 | Sebastian偏好，保持一定控制权 |

### Claude Code的独特价值

> **Lex**：“使用Claude Code的原因之一是培养用英语编程的技能……在设计层面宏观引导，而不是微观管理代码生成的细节。”
> 

**Sebastian的观察**：
- 仍不完全信任完全自动化的方式
- Codeium提供了”帮助但不完全接管”的平衡点
- 重要的是既利用AI能力又保持对过程的理解

### 专业开发者AI使用调查

基于791名10年以上经验开发者的调查：
- **大多数开发者**在生产代码中使用50%以上的AI生成代码
- **资深开发者**比初级开发者更可能使用超过50%的AI代码
- **约80%的开发者**认为使用AI让工作更有趣

---

## 开源与闭源模型格局

### 2025年主要开源模型

**可以快速列举的模型**：
- **中国**：DeepSeek、Kimi、MiniMax、Z.ai、Moonshot、Qwen
- **西方**：Mistral AI、Gemma、gpt-oss-120b、NVIDIA Nemotron 3、OLMo、SmolLM

### gpt-oss-120b的突破

> **Sebastian**：“这是OpenAI自GPT-2以来首个真正的开源模型……它是第一个真正以工具使用为设计目标的公开开放权重模型。”
> 

**工具使用的重要性**：
- 解决幻觉问题的最佳方式是让模型调用计算器或搜索引擎
- 模型不需要记住”1998年世界杯冠军”，可以直接搜索
- 代表了范式转变，但开源生态系统尚未充分利用这一能力

### 完全开源项目

致力于发布数据和代码的项目：
- **AI2 OLMo**：发布数据和代码
- **LM360/K2**：基础模型研究所
- **Apertus**：瑞士研究联盟
- **Hugging Face SmolLM**：非常流行
- **Stanford Martini Community Project**：可通过GitHub issue实现新想法

### Llama的困境

> **Nathan**：“RIP Llama。”
> 

**问题分析**：
- Llama 4过度追求基准测试排名而非实用性
- 为了在基准测试上领先进行了过度优化
- 没有发布用户真正能运行的小模型
- 内部政治斗争和激励机制错位导致崩溃

---

## Transformer架构演进

### 从GPT-2到今天的变化

> **Sebastian**：“从GPT-2到gpt-oss-120b，架构本质上还是相同的……你可以通过添加变化从一个模型演变到另一个模型。”
> 

**主要架构演进**：

| 技术 | 模型 | 作用 |
| --- | --- | --- |
| **Mixture of Experts（MoE）** | DeepSeek | 扩大模型容量但不增加每次推理的计算量 |
| **Multi-head Latent Attention** | DeepSeek | 优化KV缓存，支持更长上下文 |
| **Group Query Attention** | 多个模型 | 减少注意力计算开销 |
| **Sliding Window Attention** | OLMo 3 | 固定窗口滚动，节省内存 |
| **RMSNorm** | 多个模型 | 替代LayerNorm的归一化方式 |

### MoE详解

> **Sebastian**：“MoE的想法是将更多知识打包进网络，但不是所有知识都同时使用……有一个路由器根据输入选择哪些专家被激活。”
> 

**关键特性**：
- 将全连接层扩展为多个”专家”（如256个）
- 路由器根据输入token选择使用哪些专家
- 数学问题和翻译任务可能调用不同的专家
- 增加训练复杂度，可能出现崩溃等问题

### 替代架构探索

- **文本扩散模型**：类似图像生成的去噪过程，可并行生成多个token
- **Mamba/状态空间模型**：固定状态压缩，长上下文更经济
- **混合架构**：如Nemotron 3，找到注意力层和压缩状态的最佳比例

---

## Scaling Laws的现状与未来

### 三个Scaling维度

| 维度 | 描述 | 现状 |
| --- | --- | --- |
| **预训练Scaling** | 计算+数据 → 预测准确率 | 已验证13个数量级，仍然有效 |
| **强化学习Scaling** | 试错学习时间 → 性能 | RLVR展示了明确的Scaling曲线 |
| **推理时Scaling** | 生成更多token → 准确率 | o1模型的核心创新 |

### 预训练的经济学

> **Nathan**：“预训练变得极其昂贵……训练这些模型的成本实际上相对于服务数亿用户的成本来说很低。”
> 

**成本结构**：
- DeepSeek预训练成本约500万美元（云计算市场价）
- AI2 OLMo 3租用集群约200万美元
- 但服务用户的推理成本是数十亿美元级别
- 千GPU租用可能每天10万美元

### 2026年的计算集群

> **Nathan**：“2026年是非常大的Blackwell计算集群——吉瓦级设施在超大规模公司上线的一年。这些都是2022-2023年签订的电力和数据中心合同。”
> 

**预期变化**：
- 模型会变得稍大一些
- 可能出现$2,000订阅服务
- 更多计算资源将推动各个Scaling维度的进步

---

## 预训练、中训练与后训练

### 三阶段定义

| 阶段 | 方法 | 目的 |
| --- | --- | --- |
| **预训练** | 在大规模语料上进行下一个token预测 | 让模型吸收知识 |
| **中训练** | 类似预训练但更专注于特定内容（如长文档） | 选择性地强化特定能力 |
| **后训练** | SFT、DPO、RLVR、RLHF等 | 解锁技能，精调风格和行为 |

### 预训练数据的演进

> **Sebastian**：“不再是扔进所有能找到的数据。现在也包括合成数据——重新表述、摘要、格式化为问答形式。”
> 

**数据处理**：
- 合成数据不是纯AI生成，而是对现有内容的重构
- 高质量数据让训练更高效
- OCR技术（如DeepSeek OCR）从PDF等提取数万亿token
- 数据混合优化可通过在小样本上训练小模型来确定

### 数据质量的重要性

> **Nathan**：“在前沿实验室，如果你想要产生影响，最好的方式就是找到更好的新数据。”
> 

**关键领域**：
- Reddit数据非常有价值（但需要过滤）
- arXiv和科学PDF是重要数据源
- AI2运营Semantic Scholar，积累了大量开放获取的科学PDF
- 数据质量胜过数量

---

## 后训练前沿：RLVR与RLHF

### RLVR（带可验证奖励的强化学习）

> **Nathan**：“有趣的事实：我在的团队创造了RLVR这个术语，来自我们在DeepSeek之前的Tulu 3工作。”
> 

**工作原理**：
1. 模型生成对问题的回答
2. 验证答案是否正确（如数学题、代码运行结果）
3. 正确性作为强化学习的奖励信号
4. 模型自主学习分步推理来提高准确率

**关键突破**：
- DeepSeek R1论文中的”aha moment”：模型自己发现错误并纠正
- 训练越长，模型生成的推理步骤越长
- 不需要人工标注中间步骤，只需要问题和答案

### RLVR vs RLHF的区别

| 特性 | RLVR | RLHF |
| --- | --- | --- |
| **奖励信号** | 可验证的正确性 | 人类偏好 |
| **Scaling特性** | 有明确的Scaling Law | 过度优化问题，不能无限Scale |
| **适用领域** | 数学、代码、可验证事实 | 风格、格式、语气、人格 |
| **训练时长** | 可以训练几周获得持续提升 | 达到一定点后收益递减 |

### Sebastian的RLVR实验

> **Sebastian**：“我在MATH-500上用RLVR训练Qwen 3基础模型。模型从15%准确率，仅用50步就达到了50%。50步里模型不可能学到任何数学新知识，知识已经在预训练中了，RLVR只是解锁它。”
> 

---

## AI学习与职业建议

### 从零开始构建LLM

> **Sebastian**：“如果代码能运行，你就知道它是对的。不会有误解。这就是编程的美妙之处——它不会撒谎，它就是数学。”
> 

**学习路径**：
1. 从GPT-2实现开始（足够简单，可在单GPU运行）
2. 使用Hugging Face Transformers的预训练权重验证你的实现
3. 逐步添加新组件（MoE、Group Query Attention等）
4. 通过对比参考实现来学习

**推荐资源**：
- Sebastian的书：《Build a Large Language Model from Scratch》
- Sebastian的书：《Build a Reasoning Model from Scratch》
- Nathan的书：《Reinforcement Learning from Human Feedback》

### 学术界vs工业界的选择

| 路径 | 优势 | 劣势 |
| --- | --- | --- |
| **学术界** | 发表论文获得署名、更有成就感、指导学生 | 薪资低、资源受限、资金不确定 |
| **工业界（前沿实验室）** | 高薪（OpenAI平均年薪超100万美元股票）、前沿资源 | 无法公开发表、成为”齿轮” |
| **开放研究机构（如AI2）** | 兼顾发表和资源 | 资源仍不如最大的闭源实验室 |

### 低计算资源下的研究贡献

> **Nathan**：“如果你从一个没有计算资源的小大学出发，找到Claude失败的地方，然后下一个Claude模型的博客文章里有你的评估——这就是你的职业火箭。”
> 

**可行路径**：
- 专注于评估（Evaluation）研究
- 发现模型的新失败模式
- 深入研究非常狭窄的领域（如Character Training）
- 使用闭源模型API进行研究

---

## 硅谷AI工作文化

### 996文化

> **Lex**：“996指的是上午9点到晚上9点，一周6天。这基本上是AI公司在硅谷的标准吗？”
> 

**Nathan的观察**：
- 虽然不完全如此极端，但确实有这种趋势
- Anthropic以文化紧密、员工高度一致著称
- OpenAI看起来混乱但总能交付成果
- Apple中国供应链的工程师有”挽救婚姻”项目

### 硅谷泡沫

> **Nathan**：“’永久下层阶级’是硅谷meme之一——2025年下半年是在AI创业或模型中建立持久价值的唯一窗口期，否则所有价值都会被现有公司捕获。”
> 

**Lex的观察**：
- 硅谷是一个回音室和泡沫
- 可能与美国其他地区和世界脱节
- 泡沫可以是正面的（现实扭曲力场推动创新）
- 但也需要走出泡沫，了解更广泛的人群需求

---

## 新兴技术方向

### 文本扩散模型

> **Sebastian**：“文本扩散模型可以同时生成多个token……承诺更高效率，但如果要达到相同质量，需要更多去噪步骤，最终可能消耗相同的计算量。”
> 

**应用场景**：
- 代码Diff生成（一次性生成大量代码变更）
- Google宣布推出Gemini Diffusion
- 可能成为免费层或快速响应的选项

**局限性**：
- 推理任务和工具使用需要顺序执行，不适合并行
- 目前没有大规模部署的文本扩散模型

### 工具使用（Tool Use）

> **Sebastian**：“解决幻觉的最佳方式之一是不要总是试图记忆信息或编造。做数学题时为什么不用计算器或Python？”
> 

**当前状态**：
- gpt-oss-120b是首个以工具使用为核心设计目标的开放模型
- 开源生态系统尚未充分利用工具调用模式
- 信任问题：用户不愿让LLM访问敏感工具（如邮件）
- 需要容器化等安全措施

### 持续学习（Continual Learning）

> **Nathan**：“语言模型在解决很多任务上很强，但一个关键里程碑是AI能否像员工一样从反馈中快速学习。”
> 

**两种路径**：
1. **权重更新**：真正的持续学习，但成本高昂
2. **上下文学习**：通过提供更多上下文让模型”看起来”在学习

**现实情况**：
- 从GPT-5到5.1到5.2的迭代就是某种形式的持续学习
- 但个性化的权重更新太昂贵
- 可能需要等到设备端模型普及

### 长上下文

**技术进展**：
- GPT-5.2长上下文能力从30%提升到70%
- 预期今年达到200万甚至500万token
- 但1亿token需要真正的突破

**注意力机制创新**：
- DeepSeek-V3.2有稀疏注意力机制
- 用轻量级索引器选择需要关注的token
- 混合架构：结合全注意力层和压缩状态

---

## AGI时间线与展望

### AGI定义的共识

> **Nathan**：“我推回说有很多分歧，但很多人说类似的话——能够完成大多数数字经济工作的东西。远程工作者是一个相当合理的例子。”
> 

**核心定义层级**：
1. **远程工作者替代**：能执行大多数数字工作任务
2. **超级编码AI**：完全自主的编程能力
3. **超级AI研究员**：能够独立进行AI研究
4. **ASI**：超越人类所有能力的通用智能

### AI27报告的预测

> **Lex**：“AI27报告预测超级编码AI可能在2031年前实现，从之前的2027-2028推迟了3-4年。”
> 

**预测路径**：
1. 超级编码AI
2. 超级AI研究员
3. 超级智能AI研究员
4. 完整ASI

**Nathan的观点**：
- AI在某些方面已经超人（如前端开发），但分布式机器学习训练仍然困难
- “锯齿状”进步：某些领域超强，某些领域很弱
- 研究是混乱的、社会性的，很大程度上依赖于AI模型无法处理的数据

### 编程自动化的时间线

> **Nathan**：“到今年年底，被自动化的软件量将会非常高。但分布式机器学习训练仍然会很难。”
> 

**近期预期**：
- 今年年底：前端开发、数据分析大部分可自动化
- 1-2年：简单功能开发可能完全自动化
- 更长期：核心基础设施、分布式系统仍需人类

---

## AI商业化与行业整合

### 订阅与广告模式

> **Nathan**：“如果要在AI里投放广告，第一版广告不会很好，因为这是一个我们不知道怎么解决的难题。”
> 

**当前格局**：
- 竞争阻止了广告投放（竞争对手没有广告就会流失用户）
- OpenAI ChatGPT有约8亿用户
- 预期出现$2,000订阅服务

### 2026年可能的收购

| 公司 | 估值 | 收购方 |
| --- | --- | --- |
| **Groq** | 约200亿美元 | NVIDIA（传闻） |
| **Scale AI** | 近300亿美元 | 未知 |
| **Perplexity** | 未公开 | Apple（传闻） |

**整合趋势**：
- 许可交易取代完全收购（避免反垄断）
- 中国公司MiniMax和Z.ai已提交IPO申请
- 创业公司估值极高但盈利能力存疑

### 主要AI公司的未来

| 公司 | 前景 | 关键因素 |
| --- | --- | --- |
| **OpenAI** | 保持领先但面临竞争 | 组织混乱但能持续交付创新 |
| **Anthropic** | 软件和企业市场持续成功 | 文化紧密、代码优先策略 |
| **Google** | Gemini将蚕食ChatGPT份额 | TPU自研、数据中心先发优势 |
| **Meta** | Llama前途未卜 | 内部政治问题、可能转向闭源 |
| **xAI** | 不确定但有潜力 | 即将拥有吉瓦级计算集群 |

---

## ADAM项目：美国开源AI倡议

### 项目背景

> **Nathan**：“ADAM项目——American Truly Open Models——始于我称之为’美国DeepSeek项目’的想法。”
> 

**核心论点**：
1. 开源模型是AI研究的引擎——这是人们的起点
2. 因此控制最佳开源模型的国家将主导AI研究
3. 美国应该建设最好的模型，让最好的研究在美国发生

### 现状与差距

> **Nathan**：“2025年7月，有四五个DeepSeek级别的中国开源模型，美国为零。”
> 

**支持力度**：
- NSF向AI2授予1亿美元四年资助（NSF历史上最大的CS资助）
- NVIDIA更积极发布开源模型（Nemotron系列开始发布数据）
- Reflection AI宣布20亿美元融资专注美国开源模型
- 2025年AI Action Plan包含开源AI专门章节

### 开源对教育的重要性

> **Sebastian**：“如果只有闭源模型，你如何培养下一代人才？你只能在加入公司后才能学习。但那时你怎么识别和招聘人才？开源对很多事情都至关重要。”
> 

---

## 人类文明的未来

### 100年后的世界

> **Sebastian**：“我认为100年或200年后，定义性的技术仍然会是’计算’这个总称。不一定是AI。可能仍然是计算机。”
> 

**预测**：
- 专业化机器人会存在，部分人形
- 脑机接口可能普及
- 手机形式可能改变但不会消失（人们需要私有信息存储）
- 人类对代理感和社区的需求不会改变

### AI对人类的真正价值

> **Lex**：“让所有人类知识都能为全世界所获取……这是真正的影响。这不仅是在美国，而是全世界。”
> 

**关键洞察**：
- LLM与Google搜索有本质区别
- 可以学习人类历史上的任何知识
- 全球儿童获得平等的学习机会
- 长期来看，这就是人类如何到达火星、实现千百个创新

### 关于AI slop的担忧与希望

> **Nathan**：“接下来几年肯定会更加重视实体商品和活动……slop才刚刚开始。我希望社会在slop中淹没到足以清醒过来。”
> 

---

## 关键语录

### 关于竞争格局

> **Sebastian**：“在2026年的今天，我不认为会有任何公司独占其他公司无法获得的技术。研究人员经常换工作和实验室。思想不会是专有的，差异化因素将是预算和硬件限制。”
> 

### 关于Scaling Laws

> **Nathan**：“它已经在13个数量级的计算上成立了，为什么会停止？我认为从根本上说它不太可能停止，只是最终我们甚至无法测试更大的规模，因为伴随更多计算而来的所有问题。”
> 

### 关于开源模型

> **Nathan**：“如果禁止开源模型发布——这实际上是不可能的，除非美国建立自己的防火长城。训练这些模型的成本，无论是100万还是1亿美元，都是世界上大量想要产生影响力的人可以承担的。”
> 

### 关于学习与AI

> **Sebastian**：“如果代码能运行，你就知道它是对的。不会有误解。这就是编程的美妙之处——它不会撒谎，它就是数学。”
> 

### 关于意识与人性

> **Sebastian**：“让我们与AI非常不同、让我不担心AI接管的是意识。我们人类决定我们想做什么。AI在当前实现中，你必须告诉它该做什么。代理仍然在你手中。”
> 

### 关于人类文明

> **Nathan**：“我认为我们会没事的。人类就是为了拥有社区并找到解决问题的方法而生的。这就是让我们走到今天的原因。”
> 

---

## 术语表

| 术语 | 全称/解释 |
| --- | --- |
| AGI | 通用人工智能（Artificial General Intelligence） |
| ASI | 人工超级智能（Artificial Superintelligence） |
| LLM | 大型语言模型（Large Language Model） |
| MoE | 混合专家模型（Mixture of Experts） |
| RLHF | 来自人类反馈的强化学习（Reinforcement Learning from Human Feedback） |
| RLVR | 带可验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards） |
| KV Cache | 键值缓存（Key-Value Cache），用于加速Transformer推理 |
| SFT | 监督微调（Supervised Fine-Tuning） |
| DPO | 直接偏好优化（Direct Preference Optimization） |
| GRPO | 组相对策略优化（Group Relative Policy Optimization） |
| PPO | 近端策略优化（Proximal Policy Optimization） |
| FP8/FP4 | 8位/4位浮点数，用于降低训练和推理的内存占用 |
| 996 | 上午9点到晚上9点，每周6天的工作制度 |
| OCR | 光学字符识别（Optical Character Recognition） |
| TPU | 张量处理单元（Tensor Processing Unit），Google自研AI芯片 |
| ADAM | 美国真正开源模型（American Truly Open Models）项目 |
| AI2 | Allen Institute for AI |

---

*文档生成时间：2026年2月6日视频ID：EV7WhVT270Q*