# 20260203 Lex_Fridman_Podcast_Sebastian_Raschka（机器学习研究院）与Nathan_Lambert访谈_2026年AI现状_整理文档

# 2026年AI现状：LLM、编程、Scaling Laws、中国、Agent、GPU、AGI

## 视频基本信息

| 项目 | 内容 |
| --- | --- |
| **视频标题** | State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI |
| **视频链接** | https://www.youtube.com/watch?v=EV7WhVT270Q |
| **发布时间** | 2026年2月3日（估计） |
| **视频时长** | 4小时25分钟10秒 |
| **节目名称** | Lex Fridman Podcast #490 |
| **嘉宾** | Sebastian Raschka（机器学习研究员、《Build a Large Language Model from Scratch》作者）、Nathan Lambert（AI2 后训练负责人、《The RLHF Book》作者） |
| **主持人** | Lex Fridman |
| **播放量** | 486,965次观看 |

---

## 目录

1. [核心观点与预测](about:blank#%E6%A0%B8%E5%BF%83%E8%A7%82%E7%82%B9%E4%B8%8E%E9%A2%84%E6%B5%8B)
2. [中美AI竞争格局](about:blank#%E4%B8%AD%E7%BE%8Eai%E7%AB%9E%E4%BA%89%E6%A0%BC%E5%B1%80)
3. [主流AI模型对比](about:blank#%E4%B8%BB%E6%B5%81ai%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94)
4. [AI编程工具生态](about:blank#ai%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7%E7%94%9F%E6%80%81)
5. [开源与闭源模型之争](about:blank#%E5%BC%80%E6%BA%90%E4%B8%8E%E9%97%AD%E6%BA%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%89)
6. [Transformer架构演进](about:blank#transformer%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B)
7. [AI Scaling Laws现状](about:blank#ai-scaling-laws%E7%8E%B0%E7%8A%B6)
8. [AI训练流程解析](about:blank#ai%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90)
9. [后训练前沿研究](about:blank#%E5%90%8E%E8%AE%AD%E7%BB%83%E5%89%8D%E6%B2%BF%E7%A0%94%E7%A9%B6)
10. [AI入门学习建议](about:blank#ai%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE)
11. [AI行业工作文化](about:blank#ai%E8%A1%8C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E6%96%87%E5%8C%96)
12. [硅谷的泡沫与回音室](about:blank#%E7%A1%85%E8%B0%B7%E7%9A%84%E6%B3%A1%E6%B2%AB%E4%B8%8E%E5%9B%9E%E9%9F%B3%E5%AE%A4)
13. [新兴技术方向](about:blank#%E6%96%B0%E5%85%B4%E6%8A%80%E6%9C%AF%E6%96%B9%E5%90%91)
14. [机器人与具身智能](about:blank#%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8E%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD)
15. [AGI时间线预测](about:blank#agi%E6%97%B6%E9%97%B4%E7%BA%BF%E9%A2%84%E6%B5%8B)
16. [AI是否会取代程序员](about:blank#ai%E6%98%AF%E5%90%A6%E4%BC%9A%E5%8F%96%E4%BB%A3%E7%A8%8B%E5%BA%8F%E5%91%98)
17. [AI商业模式与并购](about:blank#ai%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F%E4%B8%8E%E5%B9%B6%E8%B4%AD)
18. [主要AI公司未来展望](about:blank#%E4%B8%BB%E8%A6%81ai%E5%85%AC%E5%8F%B8%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B)
19. [美国开源AI倡议](about:blank#%E7%BE%8E%E5%9B%BD%E5%BC%80%E6%BA%90ai%E5%80%A1%E8%AE%AE)
20. [NVIDIA与GPU未来](about:blank#nvidia%E4%B8%8Egpu%E6%9C%AA%E6%9D%A5)
21. [人类文明的未来](about:blank#%E4%BA%BA%E7%B1%BB%E6%96%87%E6%98%8E%E7%9A%84%E6%9C%AA%E6%9D%A5)
22. [关键语录](about:blank#%E5%85%B3%E9%94%AE%E8%AF%AD%E5%BD%95)
23. [术语表](about:blank#%E6%9C%AF%E8%AF%AD%E8%A1%A8)

---

## 核心观点与预测

| 观点/预测 | 提出者 | 详细说明 |
| --- | --- | --- |
| 2026年不会有任何公司拥有独占技术 | Sebastian | 研究人员频繁跳槽，技术思想流动，差异化因素将是预算和硬件资源 |
| Anthropic正赢得代码领域 | Nathan | Claude Code和Claude Opus 4.5在编程社区获得巨大关注，文化上Anthropic押注代码策略成功 |
| 中国开源模型将持续数年 | Nathan | 中国公司通过开源获取国际影响力和市场份额，预计2026年开源模型制造商比2025年更多 |
| Gemini将在2026年继续缩小与ChatGPT差距 | Nathan | Google的规模优势，加上研究与产品分离更好，而OpenAI运营混乱 |
| 预训练Scaling Laws仍然有效但低垂果实已被摘取 | Nathan | 在预训练、RL训练和推理时间扩展三个轴上仍有效，但边际收益递减 |
| 2026年将出现$2000/月订阅服务 | Nathan | 更大模型带来更高成本，从$200到$2000的10倍增长可能发生 |
| RLVR是2025年最大突破 | 两位嘉宾 | Reinforcement Learning with Verifiable Rewards实现了推理模型的能力飞跃 |
| 全自动编程工程师还需数年 | Nathan | 软件开发会大幅自动化，但研究等领域需要更长时间，“jagged”特性会持续存在 |
| Llama开源可能终结 | Nathan | Meta内部政治斗争和激励不一致导致Llama 5可能不会开源 |

---

## 中美AI竞争格局

### DeepSeek时刻的意义

2025年1月，中国公司DeepSeek发布了DeepSeek R1模型，以据称更少的计算资源和更低的成本实现了接近最先进的性能。这一”DeepSeek时刻”震惊了整个AI界。

> **Sebastian**：“DeepSeek正在赢得开源模型工作者的心，因为他们以开放模型的形式分享这些成果。”
> 

### 核心观点

**Sebastian的看法**：
- 2026年不存在任何公司拥有其他公司无法获得的技术
- 研究人员频繁更换工作和实验室
- 差异化因素将是预算和硬件约束，而非专有想法
- 目前看不到赢家通吃的局面

**Nathan的看法**：
- 各实验室对发展重点有不同侧重
- Anthropic以押注代码著称，Claude Code策略正在奏效
- 中国不仅有DeepSeek，还有Z.ai（GLM模型）、MiniMax、Kimi Moonshot等
- DeepSeek可能正在失去”中国最杰出开源模型制造商”的桂冠

### 中国开源模型的持续性

Nathan认为中国公司将持续开源数年，原因包括：
- 美国顶级科技公司出于安全考虑不会付费订阅中国公司的API
- 开源模型是获取美国AI支出市场份额的方式
- 政府会看到开源在国际上建立影响力的价值
- 2026年将有比2025年更多的开源模型制造商

### 中国模型的许可证优势

> **Sebastian**：“中国开源模型的吸引力在于许可证更加友好，基本上是无限制的开源许可证。相比之下，Llama或Gemma有一些附加条件，比如用户数超过某个阈值需要向Meta报告财务状况。”
> 

---

## 主流AI模型对比

### ChatGPT vs Claude vs Gemini vs Grok

**Claude Opus 4.5热潮**：
- 在X/Twitter社区引发巨大热度，几乎成为一个meme
- 在编程和哲学讨论方面表现出色
- 用户普遍感觉”温暖且引人入胜”

**Gemini 3**：
- Google在2025年末发布，营销和”wow因素”很高
- 但被Claude Opus 4.5的持续热度掩盖
- 在长上下文”大海捞针”测试中曾是最佳选择
- 适合快速简单查询

**ChatGPT/GPT-5**：
- 仍是用户基数最大的平台
- 品牌认知度和用户习惯形成飞轮效应
- GPT-5.2通过路由功能可能节省了大量GPU成本

**Grok 4**：
- Grok 4 SuperGrok Heavy版本在调试方面表现出色
- 适合硬核调试任务
- 适合查找实时信息或AI Twitter上的内容

### 使用模式

**Sebastian的使用习惯**：
- 日常快速查询使用ChatGPT快速模式
- 复杂任务使用Pro模式（如检查文档引用、格式错误）
- 喜欢自动模式的智能路由

**Nathan的使用习惯**：
- 只使用GPT-5.2 Thinking或Pro模式
- 经常同时运行5个Pro查询
- 信息和代码任务使用Claude Opus 4.5（始终开启扩展思考）
- 实时信息使用Grok
- 快速简单任务使用Gemini

> **Sebastian**：“你使用它直到它出错，然后你换一个LLM。这和我们使用任何东西的方式一样——文本编辑器、操作系统、浏览器。”
> 

### 为什么中国模型使用率低？

尽管中国开源模型技术优秀，但在日常使用中：
- 模型和平台之间存在差距
- 开源模型更多以开放权重而非平台著称
- 美国模型在输出质量上仍然更好
- 中国模型因出口管制使用更少GPU，导致更慢

> **Nathan**：“简单的事实是：美国模型目前更好，我们使用它们。”
> 

---

## AI编程工具生态

### 主流工具

| 工具 | 特点 | 适用场景 |
| --- | --- | --- |
| **Cursor** | IDE集成、Composer模型、每90分钟更新权重 | 代码编写、项目管理 |
| **Claude Code** | 更具代理性、自主性强 | 网站构建、数据分析、刷新工具 |
| **Codeium** | VS Code插件、聊天界面访问代码库 | 日常辅助编程 |

### Claude Code的独特价值

> **Lex**：“使用Claude Code的原因之一是培养用英语编程的技能。体验完全不同——你在设计空间层面思考，在宏观层面引导它，而不是微观管理代码生成过程。”
> 

**Nathan的经验**：
- Claude Code在处理网站构建时”就是能工作”
- 可以用一句话让它分析数据、生成图表
- 做数天工作量的事情只需几分钟

### 开发者调查数据

一项针对791名专业开发者（10年以上经验）的调查显示：
- 约80%的人发现使用AI编程更有趣或显著更有趣
- 资深开发者比初级开发者更可能在发布代码中使用50%以上的AI生成代码
- 这可能意味着专家更善于使用和审查AI代码

### 学习与享受的平衡

> **Sebastian**：“如果让AI做所有编程，两年后我还会感到满足吗？调试找到bug的感觉是世界上最棒的感觉，但如果直接让LLM解决，你永远不会有这种感觉。”
> 

---

## 开源与闭源模型之争

### 2025年主要开源模型

**中国模型**：
- DeepSeek V3、DeepSeek R1、DeepSeek-V3.2
- Qwen 3
- Kimi K2（创意写作和软件任务优秀）
- MiniMax
- Z.ai GLM模型

**西方模型**：
- gpt-oss-120b（OpenAI首个开源模型，自GPT-2以来）
- Mistral Large 3
- Gemma
- Nemotron 3（NVIDIA）
- OLMo 3（AI2）
- SmolLM（Hugging Face）

### 完全开源项目

释放数据和代码的项目：
- Allen Institute for AI (OLMo)
- Institute for Foundation Models/LM360 (K2模型)
- Apertus（瑞士研究联盟）
- NVIDIA Nemotron 3
- Stanford的Martini社区项目

### gpt-oss-120b的特殊意义

> **Sebastian**：“gpt-oss-120b是第一个真正以工具使用为目标训练的公开或开放权重模型。这是一个范式转变，解决幻觉问题的最佳方式之一就是不要总是尝试记住信息或编造——对于数学，为什么不使用计算器或Python？”
> 

### 为什么开源重要？

1. **获取用户**：让更多人使用AI，特别是无法付费的人
2. **透明度和信任**：了解模型如何工作
3. **定制化**：可以训练、添加后训练、专业化
4. **教育和人才**：训练下一代研究人员的唯一途径

---

## Transformer架构演进

### 从GPT-2到今天

> **Sebastian**：“你仍然可以从GPT-2开始，然后添加东西使其变成其他模型。它们仍然是同一血统，是一个非常接近的关系。”
> 

### 主要架构创新

| 创新 | 说明 | 代表模型 |
| --- | --- | --- |
| **Mixture of Experts (MoE)** | 多个专家网络，路由器选择性激活 | DeepSeek、Mistral Large 3 |
| **Multi-head Latent Attention** | 注意力机制的改进，压缩KV缓存 | DeepSeek |
| **Group Query Attention** | 降低KV缓存大小 | gpt-oss-120b、多数现代模型 |
| **Sliding Window Attention** | 固定窗口滚动注意力 | OLMo 3 |
| **Gated Delta Net** | 线性缩放的注意力替代 | Qwen2-VL |

### MoE详解

> **Sebastian**：“MoE的想法是在网络中打包更多知识，但不是所有知识都同时使用。在token生成期间，你更有选择性。路由器选择哪些token应该去哪个专家。”
> 

**稀疏vs密集**：
- 稀疏（Sparse）：有很多专家但只有少数活跃（MoE）
- 密集（Dense）：只有一个全连接模块，始终被利用

### 架构变化有限

尽管AI快速发展，从GPT-2到gpt-oss-120b的根本架构变化很小：
- MoE层
- Group Query Attention（从Multi-Head Attention的微调）
- LayerNorm替换为RMSNorm
- 非线性激活函数变化（类似sigmoid到ReLU）

> **Sebastian**：“真正变化的不是架构，而是训练算法、数据和系统优化。”
> 

---

## AI Scaling Laws现状

### Scaling Laws的技术定义

> **Nathan**：“Scaling Law是计算/数据与held-out预测准确率之间的幂律关系。关键发现是这种关系非常可预测。”
> 

### 三个扩展维度

| 维度 | 说明 | 现状 |
| --- | --- | --- |
| **预训练扩展** | 模型大小 × 数据集大小 | 仍有效但变得极其昂贵 |
| **RL扩展** | 强化学习训练时长 | 对数x轴，线性y轴增长 |
| **推理时间扩展** | 生成更多token解决问题 | o1引入，改变了使用方式 |

### 预训练现状

- 训练GPT-4级别模型（约1万亿参数）成本约500万美元（云市场价格）
- AI2训练OLMo 3的集群租赁成本约200万美元
- 服务成本远超训练成本（数十亿美元计算）
- 预测2026年Blackwell计算集群（吉瓦级设施）将上线

### 关键洞察

> **Sebastian**：“预训练扩展没有死亡，只是目前有其他更有吸引力的扩展方式。在某个时刻，你仍然需要在预训练上取得进展。”
> 

**预算分配考量**：
- 预训练是固定成本，能力永久存在
- 推理扩展是每次查询成本
- 需要计算用户数量和模型生命周期

---

## AI训练流程解析

### 三阶段训练

| 阶段 | 说明 | 特点 |
| --- | --- | --- |
| **预训练** | 在大规模互联网数据上进行下一个token预测 | 吸收知识，最昂贵 |
| **中间训练** | 与预训练类似但更专业化 | 长上下文文档、质量数据 |
| **后训练** | SFT、DPO、RLVR、RLHF等 | 技能解锁，相对便宜 |

### 预训练数据

- 数据集规模以万亿token计量
- 小型研究模型：5-10万亿token
- Qwen文档记载：高达50万亿token
- 闭源实验室传言：可达100万亿token

### 合成数据的新定义

> **Nathan**：“很多人认为合成数据对训练模型不好。但DeepSeek等实验室的Almost-OCR可以从PDF提取数万亿候选token用于预训练。这种字符识别数据在实验室中被描述为预训练的合成数据。”
> 

### 数据质量的重要性

- OLMo 3用更少数据训练但获得更好性能
- 关键是数据质量而非数量
- 数据混合优化：从不同来源采样小样本，训练小模型测量性能，线性回归找到最优配比

---

## 后训练前沿研究

### RLVR：2025年最大突破

**定义**：Reinforcement Learning with Verifiable Rewards

> **Nathan**：“有趣的是，我在我们的Tulu 3工作中提出了RLVR这个术语。我们不会因为是扩展RL的人而获得太多功劳，但作为学术界能做的是命名和影响话语。”
> 

**工作原理**：
1. 让模型生成答案
2. 验证答案是否正确
3. 正确率作为RL奖励
4. 模型学会通过中间步骤解决问题

### GRPO算法

**Group Relative Policy Optimization**：
- 奖励基于给定动作相对于同问题其他答案的好坏
- 如果所有问题得到相同答案，就没有信号
- 需要不断寻找更难的问题

### Sebastian的实验

> **Sebastian**：“我用RLVR在MATH-500上训练Qwen 3基础模型。基础模型准确率约15%，仅50步，几分钟内，模型从15%提升到50%准确率。50步不可能学到任何关于数学的新知识——知识已经在预训练中了，你只是在解锁它。”
> 

### RLHF vs RLVR

| 特性 | RLHF | RLVR |
| --- | --- | --- |
| 信号来源 | 人类偏好 | 可验证答案 |
| 扩展性 | 有限，会过拟合 | 可持续扩展 |
| 适用领域 | 风格、格式、个性 | 数学、代码、科学问题 |
| 计算需求 | 相对较低 | 持续增长 |

### 未来方向

1. **过程奖励模型**：对解释的中间步骤评分
2. **价值函数**：对每个token赋予价值
3. **Rubrics方法**：LLM-as-judge为每个问题定义好答案标准
4. **科学领域扩展**：将RLVR推广到更开放的领域

---

## AI入门学习建议

### Sebastian的建议

1. **从头实现简单模型**
    - 在自己电脑上运行
    - 理解预训练、监督微调、注意力机制
    - 不是为了日常使用，而是理解原理
2. **逆向工程方法**
    - 查看Hugging Face上的权重和配置文件
    - 从GPT-2模型开始添加组件
    - 加载预训练权重验证实现正确性

> **Sebastian**：“编码的美妙之处在于它不会撒谎。它是数学。如果代码有效，你就知道它是正确的。”
> 

### Nathan的建议

1. **做完基础后深入狭窄领域**
    - 很多问题只有三篇论文需要读
    - 作者可能会回复你的邮件
    - 花几周时间真正掌握狭窄领域
2. **关于学习建议的建议**
    - 第一遍离线专注模式阅读
    - 第二遍使用LLM丰富体验
    - 抵制立即查找的冲动

> **Nathan**：“我对角色训练非常感兴趣。牛津的一个学生联系我说他对此感兴趣。全世界只有两三个人非常关注这个话题，那篇论文现在存在了。”
> 

### 挣扎的价值

> **Sebastian**：“如果LLM随时都在，你真的会去挣扎吗？挣扎不愉快，但这是你成为专家的方式。也许诀窍是每天安排专门的离线学习时间。”
> 

---

## AI行业工作文化

### 996文化

- 9:00 AM 到 9:00 PM，每周6天
- 约72小时/周
- 在硅谷AI公司中日益普遍

### 前沿实验室的激情

> **Nathan**：“OpenAI的平均薪酬是每年超过100万美元的股票。对于美国任何普通人来说，进入这些AI实验室对生活是变革性的。”
> 

### 工作压力来源

- 模型相互超越，必须持续交付
- 竞争对手不断前进
- 文化上高度投入和组织化（特别是Anthropic）

### 学术界vs工业界

**学术界**：
- 薪酬低但充实感强
- 与学生合作、持续指导
- 有使命感

**工业界**：
- 高薪但可能倦怠
- 发表更少，成为”机器中的齿轮”
- 但能产生大规模影响

> **Sebastian**：“15年前和现在没有太大变化。酷的东西一直在工业界开发，是封闭的。唯一变化的是规模。”
> 

---

## 硅谷的泡沫与回音室

### SF AI Meme文化

> **Nathan**：“’永久底层阶级’是其中之一——2025年下半年是在AI初创公司建立持久价值的唯一时机，否则所有价值将被现有公司捕获，你将因此变穷。”
> 

### 泡沫的两面性

**Byrne Hobart对泡沫的分类**：
- 金融泡沫：投机，不好
- 建设泡沫：推动人们建造东西，好

> **Nathan**：“我担心AI正从建设泡沫转向金融泡沫。”
> 

### 建议

> **Lex**：“如果你真的热衷于在AI领域产生影响，身处SF是最可能实现这一目标的地方。但要走出去，阅读历史书籍、文学作品，访问世界其他地方。”
> 

---

## 新兴技术方向

### 文本扩散模型

**工作原理**：
- 从随机文本开始
- 迭代填充或细化
- 可以同时处理多个token

**优势**：
- 并行生成，可能更快
- 适合生成大型代码diff

**劣势**：
- 某些任务不适合并行（推理、工具使用）
- 质量可能需要更多去噪步骤

> **Sebastian**：“Google宣布推出Gemini Diffusion，在大多数基准测试上实现相同质量但生成速度更快。文本扩散模型不会取代自回归LLM，但可能用于快速、便宜、大规模任务。”
> 

### 工具使用

**当前状态**：
- 主要在专有LLM侧
- gpt-oss-120b是首个以工具使用为目标训练的开放模型
- 可以调用网页搜索、Python解释器等

**解决幻觉**：
- 不能完全解决，但可以减少
- LLM仍需知道何时调用工具
- 网络信息也可能不正确

### 递归语言模型

> **Sebastian**：“递归语言模型论文是一个酷想法。不是让LLM一次解决所有长上下文任务，而是分解成子任务，递归调用LLM解决。每个可能去网上收集信息，最后拼接在一起。”
> 

---

## 机器人与具身智能

### 当前状态

- 移动（Locomotion）在学习领域相对解决
- 操作（Manipulation）仍然困难
- 带入传统基于模型的方法可能有价值

### Nathan的观点

**看好**：
- 自动驾驶汽车
- 机器人自动化（如Amazon配送中心）
- 设计为”机器人优先”的新设施

**看淡**：
- 家用学习型机器人
- 消费级购买

### 安全问题

> **Lex**：“我们几乎从不讨论安全问题。所有我们讨论的学习失败模式，在LLM空间是有趣的游戏，但在机器人空间，在人们家里，在数百万分钟和数十亿交互中，你几乎不允许失败。”
> 

### 瓶颈

> **Sebastian**：“为机器人准备现实世界更难。每个人的房子都不同，这就是机器人需要在工作中学习的地方。这是目前的瓶颈：如何即时定制。”
> 

---

## AGI时间线预测

### 定义问题

> **Nathan**：“我认为有很多分歧，但很多人说类似的话：能够完成大多数数字经济工作的东西。远程工作者是一个相当合理的例子。”
> 

### AI27报告预测

**原预测**：2027-2028年
**更新预测**：2031年（均值）

**里程碑系统**：
1. 超人类编码者
2. 超人类AI研究员
3. 超智能AI研究员
4. 完整ASI

### Nathan的看法

> **Nathan**：“如果你认为进展饱和在几年内到来，开源模型将被优化得非常便宜以至于胜出。但研究是混乱的、社会的，很大程度上在AI模型无法处理的数据中。”
> 

**对AGI自动化研究**：
- 在软件方面不到10年
- 在研究等方面需要更长时间

### Sebastian的看法

> **Sebastian**：“我能看到唯一可能出错的是，如果东西被明确编程去做有害的事情。人类太聪明了，在终结者式的设置中，我认为人类会赢。”
> 

---

## AI是否会取代程序员

### 当前进展

- Claude Code在处理某些任务时已经非常强大
- Cursor每90分钟基于真实世界反馈更新模型权重
- 很多开发者已经在生产代码中使用大量AI生成代码

### Nathan的预测

> **Nathan**：“今年年底，自动化软件的数量将非常高。分布式ML等领域仍然困难，但会变得更容易。”
> 

**时间线**：
- 今年内：很多人将被推动成为设计师和产品经理
- 几年内：agent可能需要1-2天实现功能或修复bug

### 挑战

**“Jagged”特性**：
> **Nathan**：“AI在某些事情上非常出色，在某些事情上非常糟糕。当他们接近自动化软件工程师时，它会擅长传统ML系统和前端，但分布式ML因为训练数据很少而相当差。”

### 乐观信号

- Anthropic用Claude Code构建Claude Code
- 内部人员使用这些工具处理训练和生产代码
- 失败模式”相当愚蠢”，从建模角度相当可修复

---

## AI商业模式与并购

### 广告的未来

> **Nathan**：“如果AI可以让那种积极的广告观点更好地工作，对世界非常好。但这并不是说让人上瘾的推送以便展示更多内容是好事。”
> 

**当前阻碍因素**：
- 竞争对手没有做（声誉问题）
- 第一版广告不会很好

### 预期并购

| 公司 | 估值/金额 | 类型 |
| --- | --- | --- |
| Groq | 200亿美元 | 被NVIDIA收购 |
| Scale AI | 近300亿美元 | 许可交易 |
| Perplexity | - | 传言被Apple收购 |
| Manus.ai | 20亿美元 | 8个月内退出 |

### 许可交易问题

> **Nathan**：“这些许可交易对硅谷生态系统有害——顶级人才被带走，而不是完整收购让普通员工的股票变现。”
> 

### IPO展望

- 中国：MiniMax和Z.ai已提交IPO文件
- 美国：只要融资容易，不会IPO（公开市场会施加压力）

---

## 主要AI公司未来展望

### OpenAI

**优势**：
- 品牌和用户基数
- 持续能够”着陆”新研究和产品
- Deep Research、Sora、o1等定义性产品

**劣势**：
- 运营混乱
- 追逐高影响力事物（创业文化）

### Anthropic

**优势**：
- 文化上最不混乱
- 押注代码策略成功
- 员工高度一致

**预期**：
- 在软件和企业侧持续成功

### Google/Gemini

**优势**：
- 规模和历史优势
- TPU可避免NVIDIA芯片的高利润率
- 研究与产品分离更好

**劣势**：
- Google Cloud提供更复杂

### Meta/Llama

> **Nathan**：“Llama在内部政治斗争和激励不一致下崩溃了。研究人员想构建最好的模型，但有一层组织和管理试图证明他们做了这些事情。”
> 

**预期**：
- Llama 5可能不会开源
- 仍可能参与开源生态系统或继续Llama品牌

### xAI

- Grok 4在调试方面表现出色
- 计划2026年初达到1吉瓦规模，年底达到2吉瓦

---

## 美国开源AI倡议

### ATOM项目

**全称**：American Truly Open Models

**起源**：
> **Nathan**：“2025年7月，有四五个DeepSeek级别的中国开源模型，美国零个。那是我意识到我必须花精力在这上面的时刻。”

**核心主张**：
1. 开源模型将是AI研究的引擎
2. 因此拥有它们很重要
3. 美国应该构建最好的模型，让最好的研究发生在美国

### 政策支持

- AI2获得NSF 1亿美元四年资助（NSF有史以来最大的CS资助）
- 2025年美国AI行动计划包含”鼓励开源和开放权重AI”专门章节
- NVIDIA（Jensen Huang）对此非常兴奋
- Reflection AI 20亿美元融资专门用于构建美国开源模型

### 为什么重要

> **Sebastian**：“对于教育和人才，这非常重要。否则如果只有闭源模型，你只能在加入公司后学习。那时你如何雇用有才华的人？”
> 

---

## NVIDIA与GPU未来

### NVIDIA的护城河

> **Sebastian**：“NVIDIA的护城河可能不只是GPU本身，更是CUDA生态系统，这已经发展了二十年。即使在15年前我还是研究生时，我们实验室就有Tesla GPU做计算。”
> 

### 竞争格局

- Google可以制造TPU
- Amazon正在制造Trainium
- Microsoft将尝试做自己的东西
- 但NVIDIA平台最灵活

### 未来挑战

- 训练和推理计算的分离
- Groq收购意味着专门推理计算的价值
- Vera Rubin新芯片专为预填充设计

### Jensen的领导力

> **Nathan**：“公司围绕Jensen运营，他在运营上有多投入听起来与许多其他大公司如此不同。只要这是文化，我对他们的情况相当乐观。”
> 

---

## 人类文明的未来

### 100年后的世界

**技术变化**：
- 专门机器人用于特定任务
- 可能是半人形机器人
- 脑机接口
- 人们可能仍携带某种形式的私人计算设备

**不变的东西**：
- 对代理和社区的需求
- 与亲近的人一起做事
- 赋予生活意义的能力

> **Nathan**：“UBI不能解决代理问题。100年内人类生物学不会改变。”
> 

### AI的真正影响

> **Lex**：“一个很少被讨论的巨大事情是让所有人类知识对整个世界可访问。我感觉我可以问LLM任何问题并得到答案。想想跨时间的影响——世界各地的孩子能够学习这些想法。”
> 

### 工业革命的类比

**记住的东西**：
- 引擎（相当于计算机）
- 特定改变生活的机器（空调、冰箱）

**AI领域可能被记住的**：
- 计算
- 深度学习
- 可能是Transformer

### 希望的来源

> **Sebastian**：“让我们与AI如此不同的，是意识。我们人类决定我们想做什么。AI在当前实现中，你必须告诉它做什么。代理权仍在你手中。”
> 

---

## 关键语录

### 关于AI竞争

> **Sebastian**：“我不认为在2026年会有任何公司拥有其他公司无法获得的技术。差异化因素将是预算和硬件约束。”
> 

### 关于模型使用

> **Sebastian**：“你使用它直到它出错，然后你换一个LLM。这和我们使用任何东西的方式一样。”
> 

### 关于开源

> **Nathan**：“这些中国公司意识到美国顶级科技公司出于安全考虑不会付费订阅中国公司。他们看到开源模型是影响和参与美国巨大增长的AI支出市场的方式。”
> 

### 关于学习

> **Sebastian**：“代码的美妙之处在于它不会撒谎。它是数学，基本上。即使用数学，我认为你可能在书中有错误你永远不会注意到。用代码，你可以验证它。”
> 

### 关于RLVR

> **Sebastian**：“DeepSeek R1论文中令人惊叹的时刻是模型自己认识到它犯了错误，然后说’啊，我做错了，让我再试一次’。这只是给它正确答案让它找出如何做，就自然产生了。”
> 

### 关于工作文化

> **Nathan**：“我不想在这个问题上工作，因为一方面很多人把AI看作健康盟友，但它一直延伸到讨论心理健康。这让人心碎，这将是某人越过边缘的事情，但其他人可能被拯救。”
> 

### 关于AGI

> **Nathan**：“AI如此被描述为’参差不齐’——在某些事情上非常出色，在某些事情上非常糟糕。当他们接近自动化软件工程师时，会出现某些编码技能模型优秀而其他不行的情况。”
> 

### 关于人类知识

> **Lex**：“一个很少被讨论的巨大事情是让所有人类知识对整个世界可访问。这是一种渗透一切的安静力量：人类知识。”
> 

---

## 术语表

| 术语 | 全称/解释 |
| --- | --- |
| **AGI** | Artificial General Intelligence，通用人工智能 |
| **ASI** | Artificial Superintelligence，人工超级智能 |
| **MoE** | Mixture of Experts，专家混合，一种稀疏激活的神经网络架构 |
| **KV Cache** | Key-Value Cache，键值缓存，用于加速自回归生成 |
| **RLVR** | Reinforcement Learning with Verifiable Rewards，可验证奖励的强化学习 |
| **RLHF** | Reinforcement Learning from Human Feedback，人类反馈强化学习 |
| **GRPO** | Group Relative Policy Optimization，组相对策略优化 |
| **PPO** | Proximal Policy Optimization，近端策略优化 |
| **DPO** | Direct Preference Optimization，直接偏好优化 |
| **SFT** | Supervised Fine-Tuning，监督微调 |
| **LoRA** | Low-Rank Adaptation，低秩适应，一种参数高效微调方法 |
| **FP8/FP4** | 8位/4位浮点数，用于降低内存和提高训练速度 |
| **RoPE** | Rotary Position Embedding，旋转位置嵌入 |
| **YaRN** | Yet another RoPE extension，RoPE的上下文长度扩展方法 |
| **RMSNorm** | Root Mean Square Layer Normalization，均方根层归一化 |
| **CUDA** | Compute Unified Device Architecture，NVIDIA的GPU编程平台 |
| **TPU** | Tensor Processing Unit，Google的张量处理单元 |
| **ATOM** | American Truly Open Models，美国真正开放模型项目 |
| **996** | 9AM-9PM，每周6天的工作文化 |
| **Vibe Coding** | 使用自然语言描述让AI生成代码的编程方式 |
| **Compaction** | 压缩，Agent将长上下文压缩为摘要的过程 |

---

## 嘉宾简介

### Sebastian Raschka

机器学习研究员、工程师、教育者。著有《Build a Large Language Model from Scratch》和《Build a Reasoning Model from Scratch》两本书，是从零开始学习LLM的权威资源。

- X: @rasbt
- 博客: magazine.sebastianraschka.com
- YouTube频道有课程

### Nathan Lambert

Allen Institute for AI (AI2) 后训练负责人，《The RLHF Book》作者。专注于强化学习、语言模型后训练研究，是RLVR术语的提出者之一。领导ATOM项目推动美国开源AI发展。

- X: @natolambert
- 博客: interconnects.ai
- 播客: Interconnects

---

*文档生成时间：2026年2月5日*

*视频ID：EV7WhVT270QE*

*pisode: Lex Fridman Podcast #490*