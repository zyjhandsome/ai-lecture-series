# Dario Amodei —「我们正接近指数增长的终点」

## 视频基本信息

| 项目 | 内容 |
|------|------|
| **视频标题** | Dario Amodei — "We are near the end of the exponential" |
| **视频链接** | https://www.youtube.com/watch?v=n1E9IZfvGMA |
| **发布时间** | 2026年2月13日 |
| **视频时长** | 2小时22分钟19秒 |
| **节目名称** | Dwarkesh Podcast |
| **主持人** | Dwarkesh Patel |
| **嘉宾** | Dario Amodei（Anthropic CEO） |
| **点赞数** | 11,608 |
| **评论数** | 1,977 |

---

## 目录

1. [核心观点与预测](#核心观点与预测)
2. [Scaling假说与"大计算块"理论](#scaling假说与大计算块理论)
3. [RL Scaling：与预训练相同的规律](#rl-scaling与预训练相同的规律)
4. [预训练的本质：介于进化与人类学习之间](#预训练的本质介于进化与人类学习之间)
5. [经济扩散：快但不是瞬间完成](#经济扩散快但不是瞬间完成)
6. [AI编码的生产力频谱](#ai编码的生产力频谱)
7. [持续学习是否必要](#持续学习是否必要)
8. [上下文长度与在职学习](#上下文长度与在职学习)
9. [AGI时间线与具体预测](#agi时间线与具体预测)
10. [计算投资与风险管理](#计算投资与风险管理)
11. [AI实验室的盈利模式](#ai实验室的盈利模式)
12. [API定价与商业模式的未来](#api定价与商业模式的未来)
13. [Claude Code的诞生故事](#claude-code的诞生故事)
14. [AI监管与立法](#ai监管与立法)
15. [中美AI竞争与地缘政治](#中美ai竞争与地缘政治)
16. [威权主义与AI时代的治理](#威权主义与ai时代的治理)
17. [发展中国家与AI利益分配](#发展中国家与ai利益分配)
18. [Claude的宪法与价值观对齐](#claude的宪法与价值观对齐)
19. [Anthropic的公司文化与领导力](#anthropic的公司文化与领导力)
20. [关键语录](#关键语录)
21. [术语表](#术语表)

---

## 核心观点与预测

| 观点/预测 | 提出者 | 时间节点 | 详细说明 |
|---------|--------|---------|---------|
| AI底层技术指数级进步如预期 | Dario Amodei | 过去三年 | 模型从"聪明的高中生"到"聪明的大学生"再到"博士和专业水平"，代码领域甚至超越了这一水平 |
| 公众对指数终点的认知严重不足 | Dario Amodei | 当前 | 最令人惊讶的是人们仍在讨论老生常谈的政治话题，而没有意识到我们正接近指数增长的终点 |
| "数据中心里的天才之国"：1-3年内实现 | Dario Amodei | 2027-2029年 | 50/50的概率是1-2年内实现；90%的置信度是10年内实现 |
| 2030年前AI行业收入达到万亿美元 | Dario Amodei | 2030年前 | 很难想象2030年前不会有万亿美元的收入 |
| Anthropic收入每年增长10倍 | Dario Amodei | 2023-2026年 | 2023年0→1亿美元，2024年1亿→10亿，2025年10亿→90-100亿，2026年1月又增加数十亿 |
| 端到端软件工程：1-2年内实现 | Dario Amodei | 1-2年内 | 包括设定技术方向、理解问题上下文等全部内容 |
| AI编码当前生产力提升约15-20% | Dario Amodei | 当前 | 六个月前约5%，现在刚开始成为重要因素 |
| 机器人技术：在"天才之国"后再加1-2年 | Dario Amodei | "天才之国"后1-2年 | 既改进机器人设计，也改进机器人控制 |
| 经济增长率可达10-20%/年 | Dario Amodei | AI时代 | 但不会达到300%，硅谷可能达到50% |
| 行业算力每年增长约3倍 | Dario Amodei | 当前趋势 | 今年10-15 GW，明年30-40 GW，2028年约100 GW，2029年约300 GW |

---

## Scaling假说与"大计算块"理论

### "大计算块假说"（The Big Blob of Compute Hypothesis）

Dario Amodei表示，他在2017年就写了一份名为「大计算块假说」的文档，当时GPT-1刚刚发布。该文档不是专门关于语言模型Scaling的，而是对整个AI领域的更通用性论述。当时AI领域还同时存在机器人学、独立的推理研究、以及AlphaGo和OpenAI Dota中的RL Scaling。

> **Dario Amodei**："Rich Sutton在几年后发表了'苦涩的教训'（The Bitter Lesson），基本假说是一样的。"

该假说的核心观点是：**所有的巧妙方法、所有的技术、所有的"我们需要新方法来做某事"，这些都不太重要。** 真正重要的只有少数几件事：

1. **原始计算量**（raw compute）
2. **数据的数量**
3. **数据的质量和分布**——必须是广泛的分布
4. **训练时长**
5. **可以无限扩展的目标函数**——预训练目标函数是其中之一，RL目标函数（设定目标并达成目标）是另一个
6. **归一化/条件化**——确保数值稳定性
7. **层流式计算**——让大计算块以层流方式流动，而不是遇到数值问题

> **Dario Amodei**："这就是我当时的假说，也是我现在仍然持有的假说。我不认为我看到了很多不符合它的东西。"

### 当前Scaling的状态

关于预训练Scaling，Dario明确表示：

- 预训练Scaling Law仍在继续给出收益
- 现在RL阶段也在展现相同的规律
- 其他公司的发布材料也证实了这一点——在数学竞赛（AIME等）上的表现与训练时长呈对数线性关系
- 这不仅限于数学竞赛，在广泛的RL任务上都能看到同样的Scaling

---

## RL Scaling：与预训练相同的规律

### RL与预训练的类比

Dwarkesh提出了Rich Sutton的观点——真正拥有人类学习核心的系统不应该需要数十亿美元的数据和计算来学习使用Excel或网页浏览器。Dario对此回应：

> **Dario Amodei**："我认为把RL从中抽离出来是个障眼法（red herring），因为我实际上认为RL与预训练在这方面没有什么不同。"

Dario用预训练的历史进行类比：

- **GPT-1时代**（2017年）：在小数据集（如同人文学文本）上训练，不能很好泛化
- **GPT-2时代**：在整个互联网数据（Common Crawl、Reddit链接爬取）上训练后，开始获得泛化能力
- **RL同样的轨迹**：先从简单的数学竞赛RL任务开始，然后扩展到代码，现在扩展到更多任务

> **Dario Amodei**："我认为然后我们将越来越多地获得泛化能力。"

### 样本效率差异的真实性

Dario承认确实存在一个谜题：

- 预训练使用了数万亿的token
- 人类不会看到数万亿的词汇
- 这确实是一个样本效率的差异
- 模型从零开始（随机权重），需要更多的训练

但他也指出：**一旦模型训练完成，如果给它们百万token的长上下文，它们在该上下文内的学习和适应能力非常强。**

---

## 预训练的本质：介于进化与人类学习之间

Dario提出了一个关于AI学习层次结构的独特框架：

### 人类学习的层次

1. **进化**——提供先验知识，大脑不是白板
2. **长期学习**——人一生中的知识积累
3. **短期学习**——快速的情境适应
4. **人类反应**——即时反应

### LLM的学习阶段对应关系

- **预训练和RL**——介于人类进化和人类即时学习之间的中间地带
- **上下文学习（in-context learning）**——介于人类的长期学习和短期学习之间

> **Dario Amodei**："LLM的各个阶段存在于这个光谱上，但不一定恰好在同样的点上。有些人类学习模式的类比，LLM正好落在这些点之间。"

---

## 经济扩散：快但不是瞬间完成

### Dwarkesh的"扩散是借口"挑战

Dwarkesh提出了一个犀利的观点：

> **Dwarkesh Patel**："我觉得扩散是人们说的一种借口（cope）。当模型无法做某件事时，他们就说'哦，但这是扩散问题'。但你应该拿人类来比较。AI的固有优势应该使扩散对于新AI的入职来说比新人类入职容易得多。AI可以在几分钟内阅读你的整个Slack和Drive。它们可以共享同一实例的所有其他副本拥有的所有知识。"

### Dario的中间路线

Dario将世界观定位在两个极端之间：

- **极端一**：AI进展缓慢，经济扩散永远不会发生
- **极端二**：递归自我改进，纳秒级获得戴森球

> **Dario Amodei**："我们应该思考的是这个中间世界——事情极其快速，但不是瞬间完成的，需要时间是因为经济扩散、因为需要闭环。"

### 扩散的现实障碍

Dario用Claude Code的例子说明：

- Claude Code极易设置，个人开发者可以立即开始使用
- 企业开发者没有理由不像个人开发者一样快速采用
- 但大型企业仍然需要：通过法务审核、为所有人配置、通过安全合规
- 企业领导者需要理解这个产品、解释给下属、分阶段推广给数千名开发者

> **Dario Amodei**："大型金融公司、大型制药公司，它们采用Claude Code的速度远远超过企业通常采用新技术的速度。但这仍然需要时间。"

### Anthropic收入的指数增长

| 年份 | 年化收入 | 增长 |
|------|---------|------|
| 2023年 | 0 → 1亿美元 | — |
| 2024年 | 1亿 → 10亿美元 | 10倍 |
| 2025年 | 10亿 → 90-100亿美元 | ~10倍 |
| 2026年1月 | 年化100亿基础上又增加数十亿 | 持续 |

> **Dario Amodei**："显然这条曲线不能永远持续下去。GDP只有这么大。我甚至猜测今年这条曲线可能会有所弯曲，但那是一条非常快的曲线。"

---

## AI编码的生产力频谱

Dario详细阐述了AI编码能力的一个频谱，强调人们经常混淆这些非常不同的阶段：

### 编码能力的完整频谱

| 阶段 | 描述 | 状态 |
|------|------|------|
| 90%的代码由AI编写 | 行数层面 | **已实现**（Anthropic内部及下游用户） |
| 100%的代码由AI编写 | 行数层面 | 与90%有显著差异 |
| 90%的端到端SWE任务由模型完成 | 包括编译、环境搭建、测试、写文档 | 进行中 |
| 100%的今天SWE任务由模型完成 | 全部当前任务 | 接近中 |
| 软件工程师做更高层级的新工作 | 管理、指导AI | 过渡阶段 |
| SWE需求减少90% | 整体市场影响 | 长期趋势 |

> **Dario Amodei**："90%的代码由模型编写——这已经发生了，至少在某些地方。但这实际上是一个非常弱的标准。人们以为我在说我们不需要90%的软件工程师了。这两件事是完全不同的世界。"

### 编码模型的竞争优势

关于为什么拥有最好编码模型的公司没有产生持久优势：

> **Dario Amodei**："我认为我的情况模型是，优势在逐渐增长。我会说现在编码模型大约给你15-20%的总体速度提升。这是我的看法。六个月前，大概是5%。所以当时不重要。5%根本察觉不到。现在刚刚到了它成为几个重要因素之一的程度。"

Dario还坦言："我们也不是完美地防止了其他一些公司在内部使用我们的模型。"

---

## 持续学习是否必要

### Dwarkesh的核心质疑

Dwarkesh从自身经验出发提出了一个重要质疑：

> **Dwarkesh Patel**："多年来，我一直试图为自己构建各种内部LLM工具。通常我有这些纯文本输入、文本输出的任务，这应该完全在这些模型的能力范围内。但我仍然雇佣人类来做。LLM可能在这些任务上做到七分，但没有一种持续的方式可以与它们互动来帮助它们做得更好，就像我可以和人类员工那样。"

### Dario的反驳：编码的先例

Dario认为编码领域的经验表明持续学习可能并非必需：

> **Dario Amodei**："在编码代理方面，我不认为人们会说'在职学习'是阻止编码代理做所有端到端工作的因素。"

他给出了Anthropic内部的例子：
- 有工程师已经不再自己写任何代码
- GPU内核、芯片设计，以前自己写，现在让Claude来做
- 对代码库的熟悉度或"模型没有在公司工作一年"的感觉，并不是主要抱怨

### 代码库作为外部记忆支架

Dwarkesh提出了一个精到的反驳：

> **Dwarkesh Patel**："你不觉得编码之所以进展快，恰恰是因为有一个外部的记忆支架——代码库——存在吗？我不知道有多少其他工作拥有这个。编码之所以快速进步，恰恰是因为它有这个独特的优势，而其他经济活动没有。"

Dario承认这一点有道理，但指出这意味着：**通过将代码库读入上下文，模型就获得了人类需要"在职学习"才能获得的一切。**

---

## 上下文长度与在职学习

### 当前上下文长度的瓶颈

Dwarkesh指出：
- 从GPT-3到GPT-4 Turbo，上下文从2000增长到128K
- 过去两年左右，一直停留在相似的范围
- 当上下文长度远超此范围时，人们报告模型考虑完整上下文的能力出现质的下降

### Dario的回应：这是工程问题，不是研究问题

> **Dario Amodei**："这不是一个研究问题。这是一个工程和推理问题。如果你想提供长上下文，你必须存储你的整个KV缓存。在GPU中存储所有内存、调度内存，这些都是困难的。"

他解释了质量下降的原因：

- **训练上下文长度**和**服务上下文长度**是两回事
- 如果在短上下文长度上训练，然后试图在长上下文长度上服务，可能会出现质量下降
- 在长上下文长度上训练可能更困难，但这是工程问题
- 百万token是很多的——相当于人类数天到数周的学习量

### Dario的综合判断

> **Dario Amodei**："我认为在现有范式内，仅仅通过预训练泛化和RL泛化，这两样东西可能就足以让你获得'数据中心里的天才之国'。我不确定，但我认为它们会让你达到很大一部分。可能会有差距，但我确信仅凭现有的东西，就足以产生数万亿美元的收入。"

关于持续学习（continual learning）：

> **Dario Amodei**："我们也在研究这个。有很大的机会在未来一两年内我们也能解决这个问题。我认为在没有它的情况下你也能走大部分的路。"

---

## AGI时间线与具体预测

### "数据中心里的天才之国"

Dario对AGI时间线给出了分层的预测：

| 置信度 | 时间范围 | 内容 |
|--------|---------|------|
| ~50%（直觉） | 1-2年（最多1-3年） | 获得"数据中心里的天才之国" |
| ~90% | 10年内 | 所有这些一定会发生 |
| ~95-99% | 极高置信度 | 在可验证任务上实现（编码等） |
| 微小不确定性 | 长期 | 不可验证任务：规划火星任务、CRISPR级科学发现、写小说 |

> **Dario Amodei**："我认为说2035年前这不会发生是疯狂的。在某个理性的世界里，这应该是主流之外的看法。"

### 关于验证性与泛化

Dwarkesh指出：**对验证性的强调暗示了对模型泛化能力的怀疑。**

Dario回应：

> **Dario Amodei**："不，这就是为什么我几乎确定。我们已经看到了从可验证事物到不可验证事物的大量泛化。我们已经在看到这一点了。"

他将不确定性定义为：**我们完成所有可验证的事情，其中许多泛化了，但我们没有完全填满另一边。**

### Anthropic的官方预测

Anthropic曾预测到2026年底或2027年初，AI系统将拥有：
- 驾驭人类数字工作中现有界面的能力
- 达到或超过诺贝尔奖得主的智力能力
- 与物理世界交互的能力

---

## 计算投资与风险管理

### 计算投资的博弈论

Dario详细解释了为什么不能简单地购买尽可能多的计算资源：

> **Dario Amodei**："如果我的收入不是1万亿美元，哪怕只是8000亿，世界上没有任何力量、任何对冲能阻止我破产。即使我大脑的一部分在想它会不会继续以10倍增长，我也不能在2027年购买每年1万亿美元的计算资源。"

关键制约因素：
- 数据中心需要一到两年才能建成
- 如果增长率是每年5倍而非10倍，就会破产
- 如果时间点只差一年，也可能破产

### 行业整体计算规模

| 年份 | 行业总算力（GW） | 估算每GW成本 |
|------|-----------------|-------------|
| 2026年 | 10-15 GW | ~100-150亿美元/GW/年 |
| 2027年 | 30-40 GW | 同上 |
| 2028年 | ~100 GW | 同上 |
| 2029年 | ~300 GW | 同上 |

> **Dario Amodei**："你把这些加在一起，到2028或2029年，你就能得到每年数万亿美元。你正好得到你所描述的。"

### Anthropic的"负责任"投资策略

Dario解释所谓"负责任的计算投资"并不意味着绝对金额少：

- Anthropic购买的量与最大玩家相当
- 关键区别在于**是否经过深思熟虑**
- Anthropic是企业业务（enterprise business），收入更可靠、利润率更高
- 购买的量允许捕捉相当强的上行场景
- 不会捕捉到完整的10倍/年场景
- 即使情况相当糟糕，也不会陷入财务困境

> **Dario Amodei**："我的印象是其他一些公司根本没有写下电子表格，他们并不真正理解自己在承担什么风险。他们只是做看起来很酷的事情。"

---

## AI实验室的盈利模式

### 盈利的经济学原理

Dario构建了一个行业均衡的玩具模型：

**假设**：
- 50%的计算用于训练，50%用于推理
- 推理的毛利率超过50%

**推理**：
- 如果你知道确切的需求，花1000亿美元/年的计算
- 其中500亿美元支撑1500亿美元的收入（推理部分）
- 另外500亿美元用于训练
- 这样你获利500亿美元

> **Dario Amodei**："唯一使这种情况不成立的是，如果你获得的需求少于500亿美元。然后你有超过50%的数据中心用于研究，但你不盈利。"

### 为什么不将100%投入训练？

Dario使用对数回报解释：

> **Dario Amodei**："如果70%的计算用于训练只能通过1.4倍的因子获得一个稍微小一点的模型……那额外的200亿美元，每一美元对你的价值都远远低于之前的，因为对数线性的设置。所以你可能会发现，把那200亿美元投入到推理服务或雇佣更好的工程师上更好。"

### 行业结构：小数量玩家的均衡

Dario将AI行业比作云计算：

- 不是垄断（因为没有网络效应）
- 而是**少数玩家**的行业（因为进入壁垒极高）
- 云计算有3-4个玩家，AI也将有3-4个
- 原因：巨额资本需求 + 需要大量专业知识
- 模型比云计算更具**差异化**：Claude擅长不同的事，GPT擅长不同的事，Gemini擅长不同的事

> **Dario Amodei**："这不仅仅是说Claude擅长编码，GPT擅长数学和推理。比这更微妙。模型擅长不同类型的编码。模型有不同的风格。"

### 潜在的颠覆：AI模型自己制造AI模型

> **Dario Amodei**："如果生产模型的过程——如果AI模型能自己做到这一点——那可能会扩散到整个经济。但这不是商品化AI模型的论据。这更像是一次性商品化整个经济的论据。"

---

## API定价与商业模式的未来

### API模式的持久性

Dario认为API商业模式比很多人想象的更持久：

> **Dario Amodei**："如果技术在快速推进，在指数级推进，那意味着总是有一个在过去三个月内开发的新用例的前沿面。任何你建立的产品界面都总是有变得不相关的风险。"

API的价值在于：
- 总是提供最接近底层能力的接入
- 总是有上千人在尝试以不同方式实验模型
- 其中100个成为初创公司，10个成为大型成功初创公司

### Token价值的差异化

> **Dario Amodei**："不是每个模型输出的token都值同样的金额。当有人打电话说'我的Mac不工作了'，模型说'重启它'——模型已经说了这话1000万次了。也许值一美元或几分钱。而如果模型去了一家制药公司说'你正在开发的这个分子，你应该把芳香环从分子的那一端移到这一端，如果你这样做，奇妙的事情就会发生'——这些token可能值数千万美元。"

未来可能出现的商业模式：
- **按结果付费**（pay for results）
- **类似劳动的按小时计费**
- 多种模式将同时被尝试

---

## Claude Code的诞生故事

Claude Code的成功是一个"内部产品成为外部爆款"的故事：

1. Anthropic拥有自己的编码模型，且擅长编码
2. 2025年初，Dario说"我认为AI公司通过使用自己的模型可以获得不小的研究加速"
3. 鼓励内部人员实验——最初可能叫"Claude CLI"
4. 内部看到了极快的采用速度
5. Dario判断："我们已经在内部有了产品市场契合。让我们发布这个东西。"

> **Dario Amodei**："我认为就是因为我们自己在开发模型，我们自己知道最需要用模型做什么，这创造了一个反馈循环。"

为什么是编码产品而非制药公司：

> **Dario Amodei**："我的背景是生物学，但我们没有任何创办制药公司所需的资源。"

---

## AI监管与立法

### 田纳西州法案：情感支持AI

2025年12月26日，田纳西州立法机构提出法案，将"明知为AI提供情感支持（包括通过开放式对话）"定为违法。

> **Dario Amodei**："我认为那个法律很蠢。它显然是由几乎不了解AI模型能做什么和不能做什么的立法者制定的。"

### 联邦禁令之争

被投票的实际内容是：**禁止所有州对AI的监管10年，而没有任何联邦监管AI的实际计划。**

Dario的立场：

> **Dario Amodei**："鉴于我在'技术的青春期'中列出的关于生物武器和生物恐怖主义自主风险等严重危险——以及我们一直在讨论的时间线——10年是一个永恒。我认为这样做是疯狂的。"

### Dario支持的监管路径

1. **联邦政府应主动介入**——不是说"各州你们不能监管"，而是"这是我们的标准，全国适用，各州不能偏离"
2. **从透明度标准开始**——监测自主风险和生物恐怖主义风险
3. **随风险变严重逐步升级**——当更确定风险时，采取更有针对性的措施
4. **可能在今年晚些时候**——AI生物恐怖主义问题可能变得非常严重，需要行动

### 药物审批改革

> **Dario Amodei**："我实际上更担心的是药物审批流程。AI模型将大大加速我们发现药物的速度，而管道将被堵塞。我认为应该改革监管流程，使其偏向于AI带来的高安全性和高效性的药物。"

---

## 中美AI竞争与地缘政治

### 为什么不应向中国出售芯片

Dario列出了几个关键论点：

1. **攻击优势世界的风险**——任何一方都可能轻易摧毁一切
2. **不稳定性**——不像核武器有稳定的威慑均衡；如果双方对"哪个AI会赢"有不同评估，就会产生冲突风险
3. **威权政府用AI压迫人民**——建设高科技威权国家

> **Dario Amodei**："如果世界被分成两半，其中一半可能以非常难以改变的方式成为威权或极权的。"

### 关键窗口论

> **Dario Amodei**："会有一个关键时刻、少数几个关键时刻、或某个关键窗口——AI从国家安全角度赋予某些重大优势——而某个国家或联盟已经率先达到了这一点。"

Dario强调他并不主张单边控制：

> **Dario Amodei**："我不是在说某个国家或民主联盟应该说'好了，我们说了算'。另一方总是在追赶。你不愿意采取极端行动，完全控制也不是正确的。但在那个时刻，人们会理解世界已经改变了。"

### 对芯片出口管制的看法

> **Dario Amodei**："对中国的芯片出口管制——这完全符合美国的国家安全利益。这完全符合国会几乎所有人的政策信念。反对的论据，我客气地说它们很可疑。但它就是没有发生，因为有太多钱想要被赚到。"

---

## 威权主义与AI时代的治理

### 威权主义可能在道德上变得过时

Dario在《技术的青春期》中探讨了一个大胆的想法：

> **Dario Amodei**："就像封建主义基本上是一种政府形式，当我们发明了工业化，封建主义就不再可持续了。"

他对此持谨慎乐观态度：

> **Dario Amodei**："独裁可能在道德上变得过时。它们成为在道德上不可行的政府形式，由此产生的危机足以迫使我们找到另一种方式。"

### 技术是否能瓦解威权结构

Dario提出了一个思想实验：

> **Dario Amodei**："能否让一个威权国家里的每个人拥有自己的AI模型来保护他们免受监控，而威权国家又没有办法在保持权力的同时打压这种技术？"

但他也承认互联网的前车之鉴：

> **Dario Amodei**："我们最初希望社交媒体和互联网具有这种[瓦解威权的]属性，结果证明并非如此。但如果我们能带着对可能出错的事情的了解再次尝试呢？"

---

## 发展中国家与AI利益分配

### 追赶增长的挑战

Dwarkesh指出：在劳动力不再是制约因素的世界里，发展中国家通过利用未充分利用的劳动力实现追赶增长的传统机制将不复存在。

### Dario的解决方案

1. **慈善应发挥作用**，但增长应是内生的
2. **在非洲建数据中心**——只要不是中国拥有的
3. **在发展中国家发展AI驱动的制药产业**
4. **确保一些人类创业者在发展中国家**——在过渡期间，人类仍将在创办公司和监督AI模型方面发挥作用

> **Dario Amodei**："没有理由我们不应该在非洲建设数据中心。事实上，我认为在非洲建设数据中心是件好事。"

### 地理不平等的担忧

> **Dario Amodei**："我有一个担忧——增长率可能在硅谷和社会上与硅谷相连的世界部分达到50%，而在其他地方并没有比目前的速度快多少。我认为那将是一个相当糟糕的世界。"

---

## Claude的宪法与价值观对齐

### 规则 vs 原则

Dario解释了为什么使用原则比规则更有效：

> **Dario Amodei**："如果你给模型一个规则列表——'不要告诉人们怎么热线启动汽车，不要说韩语'——它并不真正理解这些规则，而且很难从中泛化。它只是一堆该做和不该做的清单。而如果你给它原则，它有一些硬性护栏如'不要制造生物武器'，但总体上你是在试图理解它应该追求什么、应该如何运作。"

### 可控性（Corrigibility）vs 内在动机

> **Dario Amodei**："关于模型的一切实际上都更接近于——它应该主要做人们想要的事情。它应该主要遵循指令。我们不是在试图构建一个自己跑去统治世界的东西。我们实际上相当偏向可控的一侧。"

但有限制：

> **Dario Amodei**："在正常情况下，如果有人要求模型做一个任务，它就应该做那个任务。但如果你要求它做危险的事情或伤害他人，模型就不愿意这样做。"

### 宪法更新的三个循环

| 循环 | 描述 | 机制 |
|------|------|------|
| **循环一** | Anthropic内部迭代 | 训练模型、不满意则修改宪法、定期公开更新 |
| **循环二** | 不同公司间的宪法竞争 | Anthropic、Google、OpenAI各自发布宪法，外部观察者比较和批评 |
| **循环三** | 社会层面的民主参与 | 此前与Collective Intelligence Project合作进行公众意见征集；可能的代议制政府参与 |

> **Dario Amodei**："我真的很喜欢循环二。整个事情必须是循环一、二、三的某种混合，只是比例问题。"

---

## Anthropic的公司文化与领导力

### Dario的时间分配

> **Dario Amodei**："我可能花三分之一、也许40%的时间确保Anthropic的文化是好的。随着Anthropic变大，直接参与模型训练、模型发布、产品构建变得更困难了。这是2500人。"

### DVQ：Dario Vision Quest

Dario每两周在全公司面前做一次约一小时的演讲：

- 有一份三四页的文档
- 讨论三到四个不同的话题
- 涵盖内部模型和产品进展、外部行业动态、全球AI和地缘政治形势
- 非常坦诚地分享想法
- 然后回答问题

> **Dario Amodei**："这种直接联系有很大的价值，这是你通过层级传递六级信息很难实现的。大部分公司的人都会来参加，无论是亲自还是远程。"

### Slack频道的直接沟通

Dario还在Slack上有一个频道：
- 经常写各种内容并大量评论
- 通常是对公司看到的事情或人们提出的问题的回应
- 内部调查中人们关心的问题，他会写出来

> **Dario Amodei**："关键是建立起告诉公司真相的声誉，直接说出事物的本质，承认问题，避免那种企业式的、防御性的沟通。"

### 与竞争对手的文化差异

> **Dario Amodei**："我们看到一些其他AI公司在成长过程中——不指名道姓——开始出现解体和内斗。我认为有些公司从一开始就有很多这种情况，只是变得更糟了。而我认为我们在把公司团结在一起、让每个人感受到使命方面做得非常出色。"

---

## 关键语录

### 关于指数增长

> **Dario Amodei**："对我来说，绝对疯狂的是你有一些人——无论是圈内还是圈外——还在讨论那些老掉牙的政治热点话题，而我们正接近指数增长的终点。"

### 关于AI进步的可预测性

> **Dario Amodei**："广义上说，底层技术的指数增长大致如我预期的那样发展。这里或那里有一两年的偏差。"

### 关于"天才之国"的实在性

> **Dario Amodei**："如果我们有了'数据中心里的天才之国'，我们会知道的。这个房间里的每个人都会知道。华盛顿的每个人都会知道。我们现在没有那个。这非常明确。"

### 关于决策的速度

> **Dario Amodei**："我的一个担忧是——某个非常关键的决定会是这样一个时刻：有人走进我的办公室说'Dario，你有两分钟。我们应该做方案A还是方案B？'有人给我一份随机的半页备忘录问'应该A还是B？'我说'我不知道。我得吃午饭。咱们选B吧。'结果这成了有史以来最重大的决定。"

### 关于历史记录的遗憾

> **Dario Amodei**："在指数增长的每一刻，外界对它理解的程度之低……这是历史中经常存在的偏见。任何实际发生的事情在回顾时都看起来是不可避免的。"

### 关于公司文化

> **Dario Amodei**："如果你有一个你信任的人组成的公司——我们努力雇佣我们信任的人——那么你就可以完全不加过滤。我认为这是公司的巨大优势。"

---

## 术语表

| 术语 | 全称/解释 |
|------|---------|
| AGI | 通用人工智能（Artificial General Intelligence） |
| RL | 强化学习（Reinforcement Learning） |
| RLHF | 基于人类反馈的强化学习（Reinforcement Learning from Human Feedback） |
| SWE | 软件工程/软件工程师（Software Engineering/Engineer） |
| Scaling Law | 规模定律——模型能力与计算、数据规模之间的数学关系 |
| MoE | 混合专家模型（Mixture of Experts） |
| KV Cache | 键值缓存（Key-Value Cache）——Transformer架构中的推理优化机制 |
| AIME | 美国数学邀请赛（American Invitational Mathematics Examination） |
| OSWorld | 计算机使用能力评测基准 |
| TAM | 总可寻址市场（Total Addressable Market） |
| DVQ | Dario Vision Quest——Anthropic内部Dario的双周全员演讲 |
| GDP | 国内生产总值（Gross Domestic Product） |
| CRISPR | 基因编辑技术 |
| FDA | 美国食品药品监督管理局（Food and Drug Administration） |
| Common Crawl | 大规模互联网爬虫数据集 |
| GW | 吉瓦（Gigawatt）——衡量数据中心电力规模的单位 |
| Cournot均衡 | 库诺均衡——寡头市场博弈论中少数厂商的产量竞争均衡 |
| Amdahl's Law | 阿姆达尔定律——系统加速受限于无法并行化部分的定律 |

---

## 参考文献与相关文档

| 文档/文章 | 作者 | 说明 |
|---------|------|------|
| 「大计算块假说」（The Big Blob of Compute Hypothesis） | Dario Amodei | ~2018年内部文档，论述AI进步的核心驱动因素 |
| 「苦涩的教训」（The Bitter Lesson） | Rich Sutton | 2019年发表，论述通用方法终将战胜人工设计的方法 |
| 「仁爱机器」（Machines of Loving Grace） | Dario Amodei | Dario关于强大AI积极影响的长文 |
| 「技术的青春期」（The Adolescence of Technology） | Dario Amodei | Dario关于AI风险、经济影响和地缘政治的长文 |

---

## 视频章节索引

| 时间戳 | 章节标题 |
|--------|---------|
| 0:00 | What exactly are we scaling?（我们究竟在Scaling什么？） |
| 12:36 | Is diffusion cope?（经济扩散是借口吗？） |
| 29:42 | Is continual learning necessary?（持续学习是否必要？） |
| 46:20 | If AGI is imminent, why not buy more compute?（如果AGI即将到来，为什么不买更多计算？） |
| 58:49 | How will AI labs actually make profit?（AI实验室实际上如何盈利？） |
| 1:31:19 | Will regulations destroy the boons of AGI?（监管会摧毁AGI的好处吗？） |
| 1:47:41 | Why can't China and America both have a country of geniuses in a datacenter?（为什么中美不能各自拥有"数据中心里的天才之国"？） |
| 2:05:46 | Claude's constitution（Claude的宪法） |

---

*文档生成时间：2026年2月19日*
*视频ID：n1E9IZfvGMA*
