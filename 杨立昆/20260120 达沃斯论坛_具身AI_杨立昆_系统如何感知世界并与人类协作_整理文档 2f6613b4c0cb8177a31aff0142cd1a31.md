# 20260120 达沃斯论坛_具身AI_杨立昆_系统如何感知世界并与人类协作_整理文档

# 具身AI：与人类共存的感知、听觉与行动系统 | AI House Davos 2026

## 视频基本信息

| 项目 | 内容 |
| --- | --- |
| **视频标题** | Embodied AI: Systems that See, Hear, and Act in the World Alongside Humans | AI House Davos 2026 |
| **视频链接** | [https://www.youtube.com/watch?v=pJyoqapCRZE](https://www.youtube.com/watch?v=pJyoqapCRZE) |
| **发布时间** | 2026年1月23日（根据活动结束日期推算） |
| **视频时长** | 54分钟17秒 |
| **活动名称** | AI House Davos 2026 |
| **嘉宾** | 杨立昆（Yann LeCun），Advanced Machine Intelligence（AMI）创始人兼执行主席 |
| **主持人** | 马克·波列费斯（Marc Pollefeys），苏黎世联邦理工学院（ETH Zürich）教授，微软空间AI实验室主任 |
| **录制地点** | 瑞士达沃斯（根据活动地点） |

---

## 目录

1. [核心观点与预测](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
2. [具身AI的定义与现状](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
3. [语言与真实世界的本质差异](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
4. [VLM、VLA与代理系统的局限](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
5. [世界模型：AI的下一个革命](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
6. [层级规划与抽象表示](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
7. [JEPA架构与V-JEPA 2](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
8. [生成式模型的根本缺陷](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
9. [自监督学习、监督学习与强化学习](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
10. [机器人学的现状与挑战](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
11. [硬件与能效的未来](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
12. [杨立昆的新公司与AI的下一次革命](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
13. [关键语录](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)
14. [术语表](20260120%20%E8%BE%BE%E6%B2%83%E6%96%AF%E8%AE%BA%E5%9D%9B_%E5%85%B7%E8%BA%ABAI_%E6%9D%A8%E7%AB%8B%E6%98%86_%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E5%B9%B6%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%8D%8F%E4%BD%9C_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202f6613b4c0cb8177a31aff0142cd1a31.md)

---

## 核心观点与预测

| 观点/预测 | 提出者 | 时间节点 | 详细说明 |
| --- | --- | --- | --- |
| LLM无法实现人类级智能 | 杨立昆 | — | 仅通过文本训练永远无法达到人类级智能，需要真实世界数据 |
| 世界模型是构建智能系统的唯一正确方式 | 杨立昆 | — | 除特殊应用外，世界模型是构建代理系统的唯一体面方式 |
| 视频数据量远超文本数据 | 杨立昆 | — | 视频数据（10^15-10^16字节）比最大LLM项目多100倍 |
| V-JEPA 2展示出常识能力 | 杨立昆 | — | 首次看到具有某种常识的模型 |
| VLA/代理系统只适用于脚本化任务 | 杨立昆 | — | 应用范围有限，像80年代的专家系统一样脆弱 |
| 下一次AI革命将由世界模型带来 | 杨立昆 | 未来几年 | 将比当前LLM更强大 |
| 人形机器人尚无法达到家猫的常识水平 | 杨立昆 | 当前 | 机器人行业的大秘密 |
| 自动驾驶尚未达到Level 5 | 杨立昆 | 当前 | 即使是Waymo也仅达到Level 4，需要完整地图和特殊传感器 |

---

## 具身AI的定义与现状

### 什么是具身AI

> 杨立昆："具身AI实际上是一种能够感知世界、理解情境、进行推理、规划并据此采取行动的人工智能。"
> 

具身AI的应用范围包括：

- 自动驾驶汽车
- 人机交互
- 机器人系统
- 工业过程控制（如涡轮喷气发动机、制造流程）

### 不仅仅是机器人

杨立昆强调，具身AI不仅限于机器人，还包括"脱离实体的物理AI"：

- 制造过程控制
- 任何以高维、连续、噪声信号形式传递数据的物理系统
- 视频处理
- 本体感受传感器

> 杨立昆："有很多不涉及机器人的应用，与语言无关的才是更准确的定义。"
> 

### 当前能力与局限

**已实现**：

- AI系统可以通过律师资格考试
- AI可以解数学题、写代码
- Waymo等公司实现了Level 4自动驾驶

**尚未实现**：

- 家用机器人
- Level 5自动驾驶（消费级）
- 具有家猫常识水平的机器人

> 杨立昆："为什么17岁的青少年在10到20小时的练习后就能学会开车？我们有数百万小时的训练数据，但训练机器学习系统模仿人类驾驶员却行不通。"
> 

---

## 语言与真实世界的本质差异

### 语言为何容易处理

杨立昆指出LLM成功的原因：

> "语言之所以像LLM那样成功，是因为它们容易掌握。"
> 
- 我们从语义层面开始处理
- Token本质上非常接近语义概念
- 可以忽略许多嘈杂复杂的真实世界细节

### 真实世界的挑战

真实世界数据的特点：

- 高维度
- 连续性
- 噪声信号

> 杨立昆："在语言学习中成功的方法，对于高维连续噪声数据不起作用，你必须使用其他方法。"
> 

---

## VLM、VLA与代理系统的局限

### VLM（视觉语言模型）

VLM的基本思路是将视觉表示与语言标记混合，然后使用LLM的机制来实现。

### VLA（视觉语言动作模型）

VLA是VLM的一个版本，其系统输出一系列动作。

### 根本缺陷

> 杨立昆："这些方法有一个重大缺陷，它们极难使其正常工作。VLA或所谓的代理系统只适用于动作遵循脚本且必须连续执行的情况。"
> 

**与80年代专家系统的相似性**：

> 杨立昆："我年纪够大，还记得80年代专家系统的发展。当时最酷的工作是做知识工程师……这种方法本质上会失败，因为结果系统非常脆弱，将知识转移到机器的成本太高。"
> 

杨立昆预测VLA/代理系统也将面临同样的命运——只在少数需要脚本化的场景中有用。

### 真正需要的是什么

> 杨立昆："如果你像我一样对构建具有猫的智能水平（更不用说人类智能）的系统感兴趣，你需要常识，需要预测行为后果的能力，需要规划能力，需要推理能力。这是VLA、VLM、LLM或任何生成式架构都无法做到的。"
> 

---

## 世界模型：AI的下一个革命

### 什么是世界模型

> 杨立昆："我无法想象我们能够构建没有能力预先预测其行为后果的智能系统。我们在世界中行动的方式是：我们知道行动的后果，我们可以预测这些后果，这使我们能够规划。"
> 

**世界模型的定义**：
给定环境在某一时刻的状态、你想要控制的系统，以及你设想的动作或干预，世界模型能够预测在t+1时刻世界或系统的状态。

### 抽象表示空间

关键洞察：

> 杨立昆："在世界模型的情况下，不需要在像素级别操作。你是在抽象表示空间中进行预测，这是一个至关重要的关键洞察，你需要真正理解它。"
> 

**为什么不能在像素级别预测**：

> "你无法预测视频中每一个细节。我可以拍摄这个房间的视频，旋转摄像机，停在这里，让系统继续拍摄。系统预测，你知道，我们在一个房间里，很可能会有一扇门在某处。但你无法预测你们每个人会长什么样，无法预测你美丽裙子的纹理……这是不可能的。"
> 

---

## 层级规划与抽象表示

### 层级规划的必要性

杨立昆用一个例子说明层级规划的必要性：

> "假设我想计划从纽约到巴黎的旅行。我坐在纽约大学的办公室里，现在是中午，我想明天去巴黎。我无法用毫秒级肌肉控制的基本人体动作来规划整个巴黎之旅，对吧？因为这太复杂了，我没有关于规划问题的相关信息。"
> 

### 层级规划的工作方式

1. **最高层**：我需要去机场赶飞机
2. **次级目标**：到达机场
3. **更具体**：走到电梯，按按钮，走出大楼
4. **最底层**：知道如何从椅子上站起来，走到门口，开门

> 杨立昆："这被称为层级规划。这是人工智能领域尚未解决的问题。人们大多已经放弃了，但这基本上是我们应该克服的巨大挑战。"
> 

### 多层级世界模型

需要构建多层级的世界模型：

- **低层级**：短期预测大量细节（如肌肉命令导致手臂移动）
- **高层级**：长期预测（如叫出租车去机场）

> 杨立昆："低层级动作无法用语言描述，而高层级动作的某些部分可以用语言描述。"
> 

---

## JEPA架构与V-JEPA 2

### 什么是JEPA

JEPA（联合嵌入预测架构，Joint Embedding Predictive Architecture）的核心思想：

> 杨立昆："学习输入信号的抽象表示，并在该抽象表示空间中进行预测，同时一起训练所有这些。"
> 

### 训练方法

1. 获取视频
2. 通过遮蔽部分视频来破坏它
3. 将完整视频输入编码器
4. 将被破坏的视频输入另一个编码器
5. 训练预测器根据部分被破坏的视频预测完整视频的表示

### 抽象层级由时间范围决定

> 杨立昆："这个系统将要学习的抽象层级取决于你训练它进行预测的时间范围。如果你训练一个系统预测未来10毫秒会发生什么，那么它可以在短期内做出非常准确的预测。这些预测很快就会与现实脱节。"
> 

### V-JEPA 2的训练与成果

- 使用相当于100年的视频进行预训练
- 系统学习如何表示视频
- 学习填补视频中的空白

**常识测试**：
通过向系统展示不可能发生的事情（如球在空中停止、变成立方体或消失）来测试：

> 杨立昆："当你用模型运行这个视频时，预测误差会飙升，因为模型说，我根本没有预测到这样的事情。这是不可能的。所以这是我第一次看到任何具有某种常识的模型，我认为这是值得期待的。"
> 

---

## 生成式模型的根本缺陷

### 生成式方法的问题

杨立昆在过去15年中尝试过通过视频进行自监督学习：

> "第一个十年我尝试使用带有潜变量的生成模型。目前我们能达到的最佳方法是扩散模型。用它可以制作可爱的视频。毫无疑问。但这种方法对自然视频从来不起作用。"
> 

**为什么不起作用**：

> "视频中可能发生无数合理的事情，当你训练系统在像素级别进行预测时，它能做的最好的事情就是表示所有可能帧的分布，所以你能做的最好的事情就是生成所有可能未来值的平均值。"
> 

### BERT vs MAE的对比

文本和图像的自监督学习对比：

| 领域 | 方法 | 效果 |
| --- | --- | --- |
| NLP | BERT | 非常成功 |
| 图像 | MAE（最大平均绝对误差自编码器） | 训练成本高，表示效果差 |

> 杨立昆："产生最佳图像表示的方法都是联合嵌入架构，这意味着这些架构在训练时不尝试重建像素标准。你必须允许系统忽略无法预测的信息。"
> 

### DINO vs 监督学习

> 杨立昆："对于图像，使用联合嵌入架构的自监督学习优于所有监督学习方法，即使是那些我们有大量数据的方法。这只是最近的事，只是去年。"
> 

---

## 自监督学习、监督学习与强化学习

### 蛋糕比喻

杨立昆大约10年前提出的著名"蛋糕"比喻：

> "每次我做演讲时，我都会展示一张有蛋糕的幻灯片……我当时的观点是每个人都完全沉迷于强化学习。我当时告诉人们，强化学习在样本方面非常低效。"
> 

### 学习方式的层级

| 层级 | 学习方式 | 比喻 | 说明 |
| --- | --- | --- | --- |
| **蛋糕主体** | 自监督学习 | 蛋糕本身 | 学习世界、表示、世界模型、预测 |
| **糖霜** | 监督学习/模仿学习 | 薄薄的一层 | 尝试模仿专家或人类行为 |
| **蛋糕顶部樱桃** | 强化学习 | 极小的部分 | 像微调一样，因为效率太低 |

> 杨立昆："大多数动物不经历监督学习阶段，因为它们从未见过父母。像章鱼从未见过它们的父母。在短短几个月内，它们变得非常聪明。它们只活两年。"
> 

### 为什么强化学习不够

> 杨立昆："如果一辆车沿着悬崖边行驶，它必须掉下悬崖数千次才能意识到这是个坏主意。然后再掉下悬崖几千次才能意识到这是个坏主意。然后再重复几千次才能弄清楚如何不掉下悬崖，然后你遇到另一个悬崖，又得重新尝试。"
> 

### 世界模型的优势

> 杨立昆："世界模型让17岁的孩子预测，如果你在悬崖边开车并把方向盘向右打，车会冲下悬崖，不会有什么好事。这就是世界模型。它让我们能够在没有训练、没有错误的情况下处理新任务。"
> 

---

## 机器人学的现状与挑战

### 人形机器人的真相

> 杨立昆："有很多公司制造人形机器人，它们可以做那种……你知道的，像表演功夫之类的，非常强大的东西。这些都是预先计算好的。这些公司中没有一家知道如何让机器人聪明到能够正常运作。这是机器人行业的大秘密。"
> 

**局限性**：

- 只能为非常狭窄的任务进行训练
- 必须收集大量数据
- 昂贵且只适用于少数狭窄任务
- 当前机器人甚至达不到家猫的常识水平

### 自动驾驶的现状

| 级别 | 状态 | 说明 |
| --- | --- | --- |
| Level 4 | 已实现（Waymo等） | 需要完整地图、特定区域、特殊传感器 |
| Level 5 | 未实现 | 消费级完全自动驾驶尚未实现 |

> Pollefeys："我认为Level 4有点短。Waymo，我认为你可以说他们达到了Level 4级别。"
> 

> 杨立昆："确实如此，但不是Level 5。他们需要完整地图，需要控制他们在哪里、什么时候行动。他们需要特殊传感器、照明设备等等。"
> 

---

## 硬件与能效的未来

### 人脑的能效

- 人脑仅用约20瓦功率运行
- 频率约为10赫兹
- 从视觉刺激到运动响应约需100毫秒
- 决定做什么还需100毫秒
- 看到障碍物到踩刹车总共约300毫秒

### 当前硬件的问题

> 杨立昆："在大脑中，配重已经就位。每个虚拟神经元，如果你愿意这么说，都有一个物理突触和一个物理神经元。在计算机实现中，我们重复使用同一块硬件、同一块硅片来计算多个神经元和多个突触的输出。"
> 

**能耗问题**：

- 必须从内存中获取数据
- 通过计算引擎处理
- 将结果写回内存
- 所有能量都消耗在从内存获取数据和写回内存上

### 解决方案的方向

需要的技术突破：

- 异步3D堆叠元件的模拟
- 纳米级非易失性存储技术
- 可能是自旋电子学、碳纳米管或某种光学器件

> 杨立昆："如果你想使用CMOS技术，它太大、太快了，你必须在神经网络的不同部分重复使用同一块硬件。你需要刷新数据。所有的能量都会消耗在那里。"
> 

### 实时视觉系统的现状

> 杨立昆："所有实时视觉系统都使用卷积网络。它们不使用Transformer。在欧洲，你的汽车、你的自动驾驶汽车，所有在欧洲销售的汽车都必须配备自动紧急制动系统……每一个都使用卷积网络，因为你需要实时数据，而你无法从Transformer获得实时数据，至少目前还不能。"
> 

---

## 杨立昆的新公司与AI的下一次革命

### 离开Meta

> 杨立昆："这是我离开Meta的一个重要原因，因为Meta最近也参与了某种重组。这可能是一个对他们有意义的战略决策，只是不是我感兴趣的。"
> 

杨立昆解释了为什么AI行业都在做同样的事情：

> "硅谷里每个人都在做同样的事情。他们都在挖同一条沟。他们互相挖角工程师，所以无法做任何不同的事情，因为如果他们开始偏离轨道，就会落后于其他人。"
> 

### 新公司的愿景

杨立昆正在创办的新公司——Advanced Machine Intelligence（AMI）：

> 杨立昆："这个想法是我们将在几年内解决这个问题，拥有能够理解物理世界或任何你提供给它们的模式的系统。可以构建模型，可以使用这些世界模型进行规划，可以构建层级世界模型。所以你可以进行层级规划，然后基本上成为未来AI系统的蓝图，这些系统将比我们目前拥有的LLM强大得多。"
> 

### AI的下一次革命

> 杨立昆："正如我所说，这是一种完全不同的非生成式范式，因为这些JEPA……不使用自回归token预测，而是使用规划。这些系统可以预测其行为的后果，我认为这是构建代理系统的唯一体面方式，除了某些特殊应用。所以我预见在未来它将成为下一次AI革命。"
> 

---

## 关键语录

### 关于LLM的局限

> 杨立昆："我们的系统可以通过律师资格考试。我不会说它们和律师一样聪明。"
> 

> 杨立昆："这就是为什么我们通过训练LLM或仅通过文本训练永远无法达到人类级智能，对吧？我们需要真实世界。"
> 

### 关于世界模型

> 杨立昆："我无法想象我们能够构建没有能力预先预测其行为后果的智能系统。"
> 

> 杨立昆："你无法预测视频中会发生什么，例如，你无法预测每一个细节……这是不可能的。如果你训练一个为像素级预测设计的生成式架构，它会失败。"
> 

### 关于机器人行业

> 杨立昆："这些公司中没有一家知道如何让机器人聪明到能够正常运作。这是机器人行业的大秘密。"
> 

### 关于强化学习

> 杨立昆："如果一辆车沿着悬崖边行驶，它必须掉下悬崖数千次才能意识到这是个坏主意……瑞士很危险。"
> 

### 关于生成式AI

> 杨立昆："大约五年前，我开始意识到这一点，并开始抨击生成式模型，试图完全'洗脑'每个人放弃生成式AI。这很困难，因为每个人都把生成式AI作为指导方针。这真的让我在一些研究LLM的同事中非常不受欢迎。"
> 

### 关于AI的未来

> 杨立昆："我预见在未来它将成为下一次AI革命……我们将拥有另一次由此带来的AI革命，我正在围绕这个想法建立一家公司。"
> 

---

## 术语表

| 术语 | 全称/解释 |
| --- | --- |
| **AGI** | 通用人工智能（Artificial General Intelligence） |
| **LLM** | 大语言模型（Large Language Model） |
| **VLM** | 视觉语言模型（Vision-Language Model） |
| **VLA** | 视觉语言动作模型（Vision-Language-Action Model） |
| **JEPA** | 联合嵌入预测架构（Joint Embedding Predictive Architecture） |
| **V-JEPA** | 视频联合嵌入预测架构（Video JEPA） |
| **DINO** | 自蒸馏无标签（self-DIstillation with NO labels），一种自监督学习方法 |
| **MAE** | 掩码自编码器（Masked Autoencoder） |
| **BERT** | 双向编码器表示（Bidirectional Encoder Representations from Transformers） |
| **ConvNet** | 卷积神经网络（Convolutional Neural Network） |
| **ConvNeXt** | 现代化的卷积网络架构 |
| **ViT** | 视觉Transformer（Vision Transformer） |
| **FAIR** | Facebook AI Research，Meta的基础AI研究实验室 |
| **AMI** | Advanced Machine Intelligence，杨立昆创办的新公司 |
| **Level 4/5** | 自动驾驶等级（Level 4为高度自动化，Level 5为完全自动化） |
| **SLAM** | 同时定位与地图构建（Simultaneous Localization and Mapping） |
| **System 1/2** | 心理学术语：System 1为自动化直觉反应，System 2为深思熟虑的推理 |

---

## 人物简介

### 杨立昆（Yann LeCun）

- **现任职务**：Advanced Machine Intelligence（AMI）创始人兼执行主席
- **前职务**：Meta首席AI科学家、FAIR创始主任
- **荣誉**：2018年图灵奖获得者（与Geoffrey Hinton、Yoshua Bengio共同获得）
- **主要贡献**：卷积神经网络（CNN）、反向传播算法
- **研究方向**：世界模型、JEPA架构、自监督学习

### 马克·波列费斯（Marc Pollefeys）

- **现任职务**：苏黎世联邦理工学院（ETH Zürich）计算机科学全职教授
- **兼任职务**：微软空间AI实验室主任
- **研究领域**：3D计算机视觉、SLAM、运动恢复结构
- **荣誉**：IEEE、ACM、ELLIS Fellow，Academia Europaea成员
- **主要贡献**：HoloLens 2核心视觉算法、首个完全自主视觉无人机

---

*文档生成时间：2026年1月28日视频ID：pJyoqapCRZE*