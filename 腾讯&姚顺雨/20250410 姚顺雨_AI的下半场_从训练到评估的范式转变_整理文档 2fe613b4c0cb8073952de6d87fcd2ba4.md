# 20250410 姚顺雨_AI的下半场_从训练到评估的范式转变_整理文档

# 姚顺雨：AI的下半场——从训练到评估的范式转变

## 视频基本信息

| 项目 | 内容 |
| --- | --- |
| **视频标题** | The Second Half of AI（AI的下半场） |
| **视频链接** | [https://www.bilibili.com/video/BV1c1F3zHE94](https://www.bilibili.com/video/BV1c1F3zHE94) |
| **原始博客** | [https://ysymyth.github.io/The-Second-Half/](https://ysymyth.github.io/The-Second-Half/) |
| **博客发布时间** | 2025年4月10日 |
| **演讲场合** | Stanford CS 224N、Columbia University |
| **演讲者** | 姚顺雨（Shunyu Yao） |
| **演讲者背景** | Princeton University 计算机科学系博士生（导师：Karthik Narasimhan）、ReAct 论文作者、OpenAI 研究员 |

---

## 目录

1. [核心观点与预测](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
2. [AI的上半场：方法优先于任务](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
3. [通用配方的诞生：强化学习的三要素](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
4. [推理作为行动空间的革命性意义](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
5. [AI的下半场：评估比训练更重要](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
6. [实用性问题：智能与效用的鸿沟](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
7. [记忆问题：AI系统的根本性缺陷](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
8. [评估范式的隐性假设](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
9. [关键语录](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)
10. [术语表](20250410%20%E5%A7%9A%E9%A1%BA%E9%9B%A8_AI%E7%9A%84%E4%B8%8B%E5%8D%8A%E5%9C%BA_%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E8%AF%84%E4%BC%B0%E7%9A%84%E8%8C%83%E5%BC%8F%E8%BD%AC%E5%8F%98_%E6%95%B4%E7%90%86%E6%96%87%E6%A1%A3%202fe613b4c0cb8073952de6d87fcd2ba4.md)

---

## 核心观点与预测

| 观点/预测 | 详细说明 |
| --- | --- |
| **AI正处于"中场休息"** | AI发展的上半场聚焦于训练方法和模型创新，下半场将转向定义问题和评估 |
| **强化学习终于泛化了** | 单一配方现在能够解决软件工程、创意写作、IMO级数学、计算机操控等多种任务 |
| **评估比训练更重要** | 未来的核心问题不再是"能否训练模型解决X"，而是"应该训练AI做什么，如何衡量真实进展" |
| **实用性问题是AI最重要的问题** | 尽管AI在考试中碾压人类，但在实际任务中仍不如普通人实用，这主要是评估问题而非训练问题 |
| **2025年将是Agent之年** | 因为我们终于有了通用的方式来训练智能体 |
| **记忆是被低估的核心问题** | 当前AI缺乏将短期记忆灵活转换为长期记忆的能力，类似神经科学中著名的H.M.患者案例 |

---

## AI的上半场：方法优先于任务

### 上半场的游戏规则

姚顺雨指出，AI发展至今，最有影响力的论文几乎都是关于**方法或模型**的，而非评估基准（benchmark）：

| 里程碑论文 | 使用的基准 | 引用对比 |
| --- | --- | --- |
| **Transformer** | WMT'14（机器翻译） | Transformer引用量远超基准论文 |
| **AlexNet** | ImageNet | AlexNet引用量约为ImageNet的3倍 |
| **GPT-3** | SuperGLUE | GPT-3的影响力远超基准 |
| **反向传播算法** | 一些模拟实验 | 甚至没有正式基准 |

### 为什么方法比任务更重要？

1. **方法更难、更令人兴奋**：
    - 反向传播、AlexNet、Transformer、GPT都需要非凡的创造力和工程能力
    - 而创建任务似乎相对简单——机器翻译、图像识别、下棋等都是人类已有的任务
2. **方法更通用、更有价值**：
    - Transformer不仅用于英德翻译，还推动了CV、NLP、RL等多个领域
    - 优秀的方法可以在多个基准上取得进展

> "在极端情况下，Transformer实际上比英德翻译更通用，因此影响更大。"
> 

### 上半场的成功模式

```
开发新方法/模型 → 在基准上展示提升 → 创建更难的基准 → 循环

```

---

## 通用配方的诞生：强化学习的三要素

### 从强化学习视角理解AI进展

姚顺雨提出，过去五年AI取得突破性进展，是因为我们终于找到了一个**通用配方**。要理解这个配方，需要从强化学习（RL）的视角来看。

强化学习的三个核心要素：

| 要素 | 传统观点 | 实际重要性 |
| --- | --- | --- |
| **算法** | 被认为最重要（REINFORCE、DQN、PPO等） | 可能是最简单的部分 |
| **环境** | 次要考虑 | 非常重要，但需要正确构建 |
| **先验知识（Priors）** | 几乎不考虑（从零开始训练） | **最关键的部分** |

### OpenAI的早期计划及其局限

OpenAI最初的计划非常合理：

1. 收集所有数字环境（游戏、网页交互、计算机操作）
2. 将其整合为标准化环境（Gym、Universe、World of Bits）
3. 用智能RL算法解决这些环境

**问题**：

- 在Dota、机器人手等领域取得进展
- 但始终无法解决计算机使用或网页导航
- 在一个领域训练的智能体无法迁移到另一个领域

### GPT的意外发现：先验知识是关键

> "只有在GPT-2/GPT-3之后，我们才发现缺失的部分是**先验知识**。你需要强大的语言预训练来提炼通用常识和语言知识，然后才能微调成为网页智能体（WebGPT）或聊天智能体（ChatGPT）。"
> 

**讽刺性的历史教训**：

- 长期以来，RL研究者认为算法比环境和先验更重要
- 实际上优先级应该完全颠倒：**先验 > 环境 > 算法**

> "正如乔布斯所说：你无法在向前看时把点连起来，只能在回顾时才能做到。"
> 

---

## 推理作为行动空间的革命性意义

### 先验知识与环境的匹配问题

语言预训练为聊天机器人创造了良好的先验，但对于控制计算机或玩视频游戏效果不佳。原因是：

- 这些领域与互联网文本的分布差距太大
- 简单的SFT/RL在这些领域泛化能力差

### ReAct的核心洞见

姚顺雨在2019年发现了这个问题。当时GPT-2刚发布，他在其基础上进行SFT/RL来解决文本游戏（CALM论文），但：

- 需要数百万步RL才能在单个游戏中取得进展
- 无法迁移到新游戏

**关键顿悟**：

> "我们人类能够泛化，是因为我们可以选择做的不仅仅是'去柜子2'或'用钥匙1打开箱子3'——我们还可以选择**思考**：'地牢很危险，我需要武器。没有可见的武器，也许需要在锁着的箱子里找。箱子3在柜子2里，让我先去那里打开它。'"
> 

### 推理的神奇特性

推理是一种**奇特的行动**：

- 不直接影响外部世界
- 空间是开放的、组合无限的（可以思考一个词、一句话、一段文字）
- 在经典RL理论中，这是灾难性的——想象原本两个盒子（一个有100万美元），现在加入无限个空盒子

但是：

> "通过将推理加入任何RL环境的行动空间，我们利用语言预训练的先验来泛化，并为不同决策提供灵活的测试时计算。"
> 

**直观解释**：即使加入无限个空盒子，你在一生中已经见过各种游戏中的这些盒子，选择这些盒子让你能更好地在任何给定游戏中选择有钱的盒子。

**抽象解释**：**语言通过推理在智能体中实现泛化**。

### 通用配方的形成

一旦有了正确的RL先验（语言预训练）和RL环境（将语言推理加入行动空间），RL算法可能是最简单的部分：

| 产品/模型 | 领域 | 共同配方 |
| --- | --- | --- |
| **DeepSeek R1** | 文本推理、数学、编程 | 语言先验 + 推理行动 + RL |
| **o1/o3** | 数学、编程、推理 | 语言先验 + 推理行动 + RL |
| **Operator** | 计算机操作 | 语言先验 + 推理行动 + RL |
| **Deep Research** | 长篇问答 | 语言先验 + 推理行动 + RL |

---

## AI的下半场：评估比训练更重要

### 上半场游戏被颠覆的原因

1. **配方已将基准提升标准化和工业化**：
    - 不再需要太多新想法
    - 下一代o系列模型可能提升30%，而你的新方法可能只提升5%
2. **更难的基准很快被攻克**：
    - 创建真正有挑战性的任务变得困难
    - Jason Wei的图表显示：所有领域的进展越来越快

### 评估创建者的惯性陷阱

以人类考试评估为例（如MMLU，2021年是极其大胆的想法）：

- 3年后已饱和
- 自然反应：创建更难的考试（如GPQA，博士级别）

以编程评估为例：

- 从简单编程任务到CodeForces
- 现在o3可以用50次提交赢得所有三道题
- 全球只有200人在CodeForces上比o3更强

**问题**：

> "4年前，人类考试和编程是大胆的想法。3年前仍然有意义。但现在可能不再合适，因为智能水平的提升与实用性增长不再一致。"
> 

### 实用性问题

| 对比项 | AI表现 | 实际影响 |
| --- | --- | --- |
| 博士级逻辑推理和科学知识 | 能做到我做不到的事 | — |
| 编程能力 | 远超我 | — |
| 考试（GRE、SAT、律师、医生） | 几乎碾压 | — |
| 实际任务中的实用性 | 不如大多数人 | 尚未改变50%的GDP |
| GDP训练占比 | — | 可能只有1% |

> "我们现在有博士级AI，它们比我更聪明，但仍然不如大多数人实用。解决这个问题将是AI最重要的任务。我称之为**实用性问题（Utility Problem）**。"
> 

---

## 记忆问题：AI系统的根本性缺陷

### H.M.患者的启示

姚顺雨用神经科学中著名的H.M.患者案例来类比当前AI的困境：

**H.M.的情况**：

- 海马体受损
- 每天醒来不记得前一天
- 保留童年记忆
- 缺乏将短期记忆转换为长期记忆的能力

**当前AI智能体的情况**：

- 每次解决新任务时忘记之前解决过的
- 每次聊天机器人与你对话时忘记之前的对话
- 这与H.M.患者的故事**完全相同**

### 当前记忆层级的问题

| 记忆类型 | 当前AI实现 | 问题 |
| --- | --- | --- |
| **短期记忆** | 语言模型的上下文窗口 | 任务结束后清空 |
| **长期记忆** | 语言模型的权重 | 需要训练才能更新，不够灵活 |

**核心缺陷**：缺乏灵活地将短期记忆转换为长期记忆的方式

> "我们人类可以在任何时候将短期记忆转换为长期记忆。如果你发现这个演讲很有启发，两年后你仍会记得。但语言模型缺乏这种转换的灵活性。"
> 

### 工业界的尝试

**ChatGPT记忆功能**：

- 每次对话后尝试总结关于用户的重要事实
- 下次对话时附加到提示中
- 实现个性化

**学术研究（CEO等论文）**：

- 在轨迹上微调模型
- 从轨迹中提取显著技能存入记忆库
- 下次解决任务时检索

**根本问题**：缺乏好的基准和评估方法来推动这一领域发展

---

## 评估范式的隐性假设

### 需要质疑的基本假设

姚顺雨指出，AI评估中存在许多**隐性假设**，我们从未真正质疑过：

| 假设 | 标准做法 | 现实情况 |
| --- | --- | --- |
| **评估应自动运行** | 智能体接收任务输入，自主执行，获得奖励 | 现实中智能体需要在任务过程中与人类互动 |
| **评估应独立同分布（i.i.d.）** | 500个任务并行独立执行，取平均 | 现实中顺序解决任务，逐渐熟悉业务 |
| **评估现有能力** | 测试模型当前能力 | 但最重要的可能是**学习能力** |

### 软件工程师的类比

想象一个软件工程师：

- **当前AI方式**：每天醒来对公司代码库一无所知，必须重新入职培训
- **现实情况**：解决问题后逐渐熟悉业务，能力不断提升

> "第一天的表现并不重要，真正重要的是入职六个月或七天后的表现。"
> 

### 新评估范式的方向

**已有的突破尝试**：

- **Chatbot Arena**：让真实人类参与评估
- **τ-bench**：在循环中加入用户模拟

**需要的转变**：

- 不仅是创建新任务，而是创建**新的评估设置**
- 打破现有配方有效的隐性假设
- 如果不打破这些假设，配方将持续有效

---

## 关键语录

### 关于AI发展阶段

> "我认为我们正处于AI发展的一个特殊时刻，我称之为**中场休息**。"
> 

> "从达特茅斯会议以来，AI一直聚焦于训练，目标是让AI系统越来越强大。现在，我们终于有了一种通用方法来提升任何基准。这将改变一切。"
> 

### 关于强化学习的教训

> "整个历史中，我们认为算法比环境和先验更重要。结果发现，先验可能是最关键的部分，然后需要正确构建环境，算法可能是最简单的。"
> 

> "你无法在向前看时把点连起来，只能在回顾时才能做到。"
> 

### 关于实用性问题

> "AI已经在棋类和围棋上击败世界冠军，在SAT和律师考试上超越大多数人，在IOI和IMO达到金牌水平。但世界并没有太大改变，至少从经济和GDP来看。"
> 

> "这个问题的根本原因可能出奇地简单：**我们的评估设置在许多基本方面与现实世界设置不同**。"
> 

### 关于下半场的机遇

> "上半场的玩家解决视频游戏和考试，下半场的玩家将通过构建智能化的实用产品来建立价值数十亿甚至万亿美元的公司。"
> 

> "通用配方会碾压你的增量方法，除非你创建打破配方的新假设。然后你就能做真正改变游戏规则的研究。"
> 

> "**欢迎来到下半场！**"
> 

---

## 术语表

| 术语 | 全称/解释 |
| --- | --- |
| **RL** | 强化学习（Reinforcement Learning） |
| **ReAct** | 推理与行动协同框架（Reasoning and Acting），姚顺雨2022年提出 |
| **先验（Priors）** | RL中的预训练知识，如语言模型的预训练权重 |
| **i.i.d.** | 独立同分布（Independent and Identically Distributed） |
| **WMT'14** | 2014年机器翻译研讨会基准 |
| **SuperGLUE** | 通用语言理解评估基准 |
| **MMLU** | 大规模多任务语言理解基准 |
| **GPQA** | 研究生水平问答基准 |
| **τ-bench** | 工具-智能体-用户交互基准 |
| **o1/o3** | OpenAI的推理模型系列 |
| **DeepSeek R1** | DeepSeek的推理模型 |
| **Operator** | OpenAI的计算机操作智能体 |
| **Deep Research** | OpenAI的深度研究功能 |
| **H.M.患者** | 神经科学中著名的海马体损伤病例，用于研究记忆 |
| **SFT** | 监督微调（Supervised Fine-Tuning） |
| **CEO** | 姚顺雨关于AI记忆的论文 |
| **CALM** | 基于预训练语言模型的文本游戏智能体论文 |
| **Chatbot Arena** | 通过真实用户对话评估聊天机器人的平台 |

---

## 演讲者简介

**姚顺雨（Shunyu Yao）**

- Princeton University 计算机科学系博士生（2019年至今）
- 导师：Karthik Narasimhan
- 本科毕业于清华大学（2015-2019）
- OpenAI 研究员
- **代表作**：
    - ReAct：推理与行动协同框架（ICLR 2023）
    - τ-bench：工具-智能体-用户交互基准（ICLR 2025）
    - CALM：首个基于预训练语言模型的智能体
- 研究方向：自然语言处理、语言交互、具身学习、表示学习

---

## Q&A 环节

### 关于记忆与感官体验

**问**：如何为大语言模型创建具有感官体验的评估环境？它们完全脱离物理现实，而感官体验是记忆的重要组成部分。

**答**：从强化学习角度，关键是确定你的**应用场景是什么**、**奖励机制是什么**。收集视频、声音等感官数据是相对容易的部分，真正困难的是定义任务和奖励。一旦弄清楚这些，方法论上自然会取得更多进展。

### 关于"中场休息"的比喻

**问**：这个比喻有多严肃？上半场有很多人不相信AI，经历了多次AI寒冬。这是中场表演吗——很多人唱歌跳舞，然后又变得困难？

**答**：AI寒冬与应用不足有关。如果我们相信未来会有有价值的应用，就不会再有寒冬。ChatGPT似乎是个好应用，但我们还没有很多伟大的应用，尽管在方法论上取得了重大突破。关键是：如果想要更多有价值的应用，我们必须开始思考**评估任务与现实世界应用有何不同**，以及如何弥合这个鸿沟。

---

*文档生成时间：2026年2月5日视频ID：BV1c1F3zHE94原始博客发布时间：2025年4月10日*